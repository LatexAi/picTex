{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PicTex Text Detection Model with Zach\n",
    "\n",
    "From meeting with Zach on 8/10/20 because `output tensors` weren't 1's and 0's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73 classes\n",
      "{'(': 0, ')': 1, '+': 2, '-': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, '=': 14, 'a': 15, 'alpha': 16, 'ast': 17, 'b': 18, 'beta': 19, 'c': 20, 'comma': 21, 'd': 22, 'delta': 23, 'e': 24, 'emptyset': 25, 'f': 26, 'forall': 27, 'full_stop': 28, 'g': 29, 'greater': 30, 'h': 31, 'implies': 32, 'in': 33, 'infty': 34, 'int': 35, 'j': 36, 'k': 37, 'l': 38, 'lambda': 39, 'land': 40, 'leq': 41, 'lesser': 42, 'm': 43, 'mu': 44, 'n': 45, 'nabla': 46, 'Naturals': 47, 'neq': 48, 'o': 49, 'p': 50, 'perp': 51, 'pi': 52, 'q': 53, 'r': 54, 'Reals': 55, 's': 56, 'setminus': 57, 'sigma': 58, 'sim': 59, 'sum': 60, 'supset': 61, 't': 62, 'theta': 63, 'u': 64, 'v': 65, 'varepsilon': 66, 'w': 67, 'x': 68, 'y': 69, 'z': 70, '[': 71, ']': 72}\n",
      "{0: '(', 1: ')', 2: '+', 3: '-', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: '=', 15: 'a', 16: 'alpha', 17: 'ast', 18: 'b', 19: 'beta', 20: 'c', 21: 'comma', 22: 'd', 23: 'delta', 24: 'e', 25: 'emptyset', 26: 'f', 27: 'forall', 28: 'full_stop', 29: 'g', 30: 'greater', 31: 'h', 32: 'implies', 33: 'in', 34: 'infty', 35: 'int', 36: 'j', 37: 'k', 38: 'l', 39: 'lambda', 40: 'land', 41: 'leq', 42: 'lesser', 43: 'm', 44: 'mu', 45: 'n', 46: 'nabla', 47: 'Naturals', 48: 'neq', 49: 'o', 50: 'p', 51: 'perp', 52: 'pi', 53: 'q', 54: 'r', 55: 'Reals', 56: 's', 57: 'setminus', 58: 'sigma', 59: 'sim', 60: 'sum', 61: 'supset', 62: 't', 63: 'theta', 64: 'u', 65: 'v', 66: 'varepsilon', 67: 'w', 68: 'x', 69: 'y', 70: 'z', 71: '[', 72: ']'}\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "data_dir = \"./final/\"\n",
    "\n",
    "classes = os.listdir(data_dir)\n",
    "num_classes = len(classes)\n",
    "\n",
    "classes_encode, classes_decode = {}, {}\n",
    "for i, name in enumerate(classes):\n",
    "    classes_encode[name] = i\n",
    "    classes_decode[i] = name\n",
    "\n",
    "encode_dict, decode_dict = OrderedDict(classes_encode), OrderedDict(classes_encode)\n",
    "\n",
    "print(f\"There are {num_classes} classes\")\n",
    "print(classes_encode)\n",
    "print(classes_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the `Dataset` and `Dataloader` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Choose either colored / grayscale\n",
    "num_output_channels = 1\n",
    "normal = (0.5,) # uncomment this for grayscale\n",
    "# normal = (0.5, 0.5, 0.5) # uncomment this for colored\n",
    "\n",
    "# choose batch size\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(num_output_channels),\n",
    "     transforms.Resize((32, 32)), \n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(normal, normal)])\n",
    "\n",
    "class PicTexDataset(Dataset):\n",
    "    def __init__(self, root_dir, encode_dict, num_classes, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory containing images sorted by class folders\n",
    "            encode_dict (Ordered dict): Dictionary with class names zipped from 0-(num_classes-1)\n",
    "            num_classes (int): Number of classes (SHOULD EQUAL LEN of ENCODE_DICT)\n",
    "            transform (torchvision.transforms): Transforms to be applied to images \n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.encode_dict = encode_dict\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "        \n",
    "        \"\"\"\n",
    "        Loading images:\n",
    "            all_paths (string list): Path of every image\n",
    "            all_paths_class (string list): Bijection with all_paths. Class name for each path\n",
    "            all_images (string * string list): List of these objects... (class name, path of image)\n",
    "        \"\"\"\n",
    "        all_paths, all_paths_class = [], []\n",
    "        for name in encode_dict.keys():\n",
    "            list_classes = os.listdir(root_dir + name)\n",
    "            all_paths += list(map(lambda s : root_dir + name + \"/\" + s, list_classes))\n",
    "            all_paths_class += [name] * len(list_classes)\n",
    "        \n",
    "        self.all_images = list(zip(all_paths_class, all_paths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_class, img_name = self.all_images[idx]\n",
    "        try:\n",
    "            image = Image.open(img_name)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except OSError:\n",
    "            print(img_name, img_class)\n",
    "        # image = image.unsqueeze(1)\n",
    "        \n",
    "        #label = torch.zeros(self.num_classes)\n",
    "        #label[self.encode_dict[img_class]] = 1 \n",
    "        label = self.encode_dict[img_class]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "def load_split_train_test(datadir, valid_size = .2):\n",
    "    dataset = PicTexDataset(data_dir, encode_dict, num_classes, transform)\n",
    "    num_test = int(valid_size*len(dataset))\n",
    "    num_train = len(dataset) - num_test\n",
    "    \n",
    "    train_data, test_data = random_split(dataset, (num_train, num_test))\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    return trainloader, testloader\n",
    "\n",
    "trainloader, testloader = load_split_train_test(data_dir, .15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test `Dataloader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([30, 44, 32, 13, 42, 10,  7, 33, 17, 20,  3, 70, 42, 62, 28, 52])\n",
      "Label: tensor([ 0,  3, 24,  4, 19,  6, 72, 58, 42,  5, 15, 22, 39,  3, 21, 18])\n",
      "Label: tensor([17, 12, 58, 72, 26, 71, 54, 25, 60, 68, 45, 16, 47, 18, 33, 44])\n",
      "Label: tensor([ 8, 54, 13,  3,  3, 49, 59,  6, 70, 23,  7, 58, 26, 61, 70,  7])\n",
      "Label: tensor([23, 72, 45, 40,  5, 37, 21, 63, 33, 50, 25, 14, 43, 49, 17, 38])\n",
      "Label: tensor([33, 60, 17,  3, 61, 27, 58, 56, 72,  4, 37, 40, 11,  4, 26, 45])\n",
      "Label: tensor([64, 13, 47, 25, 42, 10,  2, 54, 14, 11, 58,  5, 34, 62, 45, 62])\n",
      "Label: tensor([ 6, 45, 69, 24, 72,  5, 67, 30, 34, 29, 43, 43, 63, 52,  7,  4])\n",
      "Label: tensor([61, 11, 54, 42, 31, 34, 59, 70, 63, 45, 32, 44, 42, 47,  4, 17])\n",
      "Label: tensor([ 2, 15, 44, 19, 34, 11, 51,  9, 34, 61, 67, 55, 49, 68, 58, 13])\n",
      "Label: tensor([27, 21, 27, 62,  2, 34, 26, 55, 11,  2, 42, 72,  7, 10, 24, 57])\n",
      "Label: tensor([70, 65, 40, 66, 70, 63, 32, 22, 22, 44, 54, 53,  5, 51, 30, 27])\n",
      "Label: tensor([67,  4, 65, 42, 68, 62, 65, 26, 18, 49, 36, 47, 30, 45, 46, 57])\n",
      "Label: tensor([17, 62, 57,  8, 59, 71, 25, 20, 37, 63, 60, 40,  9, 66,  2, 20])\n",
      "Label: tensor([27, 65, 51, 54, 45, 66, 49, 42, 12, 69, 59,  3,  5, 62, 64, 56])\n",
      "Label: tensor([ 2, 56, 55, 18,  1, 45, 34, 69, 31,  8, 19, 18, 40, 36, 17,  7])\n",
      "Label: tensor([21, 45, 55, 35, 44, 13, 25, 58, 63, 56, 17, 48, 51, 58, 22, 52])\n",
      "Label: tensor([ 8, 14, 31, 21, 57, 70,  4, 30,  7, 67, 30, 18, 57,  7, 71, 68])\n",
      "Label: tensor([65, 57, 71,  0, 24, 43,  7, 44, 56, 66, 27,  4, 71, 70, 17, 11])\n",
      "Label: tensor([49, 24, 56, 12, 40, 65, 44, 20, 14, 66, 21,  0, 64, 45, 68, 68])\n",
      "Label: tensor([47, 49,  0, 38, 29, 52, 35, 16, 47, 23, 66,  8, 69, 12,  5, 68])\n",
      "Label: tensor([59, 64, 12, 17, 70, 27, 14, 68, 66, 52, 10,  7,  1, 10, 37, 54])\n",
      "Label: tensor([49, 58, 23, 63, 14, 69, 14, 45, 31, 62, 58, 17, 65, 38, 54,  6])\n",
      "Label: tensor([ 5,  8, 47, 67, 54,  7, 19, 14, 64,  9, 53, 43,  2, 14, 57, 19])\n",
      "Label: tensor([61, 12, 45, 12, 45, 34, 10, 17, 45, 33, 14,  4, 50,  1, 29, 44])\n",
      "Label: tensor([48, 19, 57, 62, 25, 64, 13, 17, 25,  3, 40, 11, 44, 46, 30, 64])\n",
      "Label: tensor([59, 35, 37,  8, 45, 12, 10, 72, 65, 56, 54, 63, 11,  4, 57, 45])\n",
      "Label: tensor([30, 54, 29, 36, 16,  0, 17,  6, 42, 54, 62, 65, 61,  8,  4, 13])\n",
      "Label: tensor([ 8, 52, 70, 55, 48, 59, 69, 51,  2, 30, 70, 15, 63, 57, 47, 39])\n",
      "Label: tensor([13,  2, 31,  3, 55, 32, 22, 39, 24, 45, 40,  8, 14, 19, 36, 34])\n",
      "Label: tensor([46, 52,  2,  3, 20, 49, 66, 18, 70, 54, 24, 30, 26, 72, 49,  8])\n",
      "Label: tensor([23,  8, 25, 20, 16, 59, 11, 58, 22, 45, 24,  4, 66, 15,  5, 35])\n",
      "Label: tensor([ 7,  3, 70, 10, 24, 63, 71, 34, 42,  7, 30,  6,  2, 45, 39,  1])\n",
      "Label: tensor([22, 72, 47, 12, 42, 45, 49, 20, 15, 29, 46, 16, 26,  2, 30,  8])\n",
      "Label: tensor([27, 51, 30,  6, 16, 42, 46, 56, 54, 44, 62, 23, 16, 72, 24, 17])\n",
      "Label: tensor([34, 65, 56, 33, 50, 11, 57, 42, 40, 26, 24, 47, 55, 38, 63,  6])\n",
      "Label: tensor([20, 23,  1,  8, 14, 27, 55, 22, 44, 17, 67, 57,  4, 55, 50, 10])\n",
      "Label: tensor([18, 47, 40, 58, 61, 20, 52,  7,  8, 24,  1, 36, 29, 60, 52, 69])\n",
      "Label: tensor([34, 38,  7,  2, 49, 19, 19, 10, 19, 51, 64, 48, 35,  1, 42, 37])\n",
      "Label: tensor([21, 30, 57, 11, 40,  6, 14, 55, 14,  2, 31, 32, 52, 60, 50, 44])\n",
      "Label: tensor([ 5, 11, 40, 72, 24, 55, 58, 55, 22, 26, 25, 33, 23, 61, 26, 23])\n",
      "Label: tensor([31,  9, 38, 26, 30, 54, 15, 10, 39, 57, 52, 40, 58, 62, 27, 11])\n",
      "Label: tensor([22, 55, 37,  2, 31,  5, 40, 59, 34, 67,  8,  4, 33, 21, 17, 27])\n",
      "Label: tensor([72, 67, 27, 17,  6, 68, 66, 71,  3, 30, 19, 17,  0, 70, 11, 25])\n",
      "Label: tensor([55, 10,  0, 57, 14, 22, 22, 49, 66,  7, 49, 40, 51, 62, 48,  0])\n",
      "Label: tensor([63, 71,  6, 23, 47,  7, 48,  9, 33, 20, 58, 16, 58, 36, 62, 41])\n",
      "Label: tensor([63, 37, 31, 56, 71, 39, 63, 15, 49, 24, 62, 26, 21,  1, 30, 34])\n",
      "Label: tensor([35, 11, 38, 42, 18, 31, 51,  8, 30, 67, 57, 15, 31, 69, 56, 34])\n",
      "Label: tensor([ 1, 71, 64, 36, 68,  1, 16,  9, 59, 22,  9, 66,  0, 22, 16, 71])\n",
      "Label: tensor([58, 54, 22,  2, 47, 27, 40, 33, 12,  8, 67, 61, 33, 37, 50,  2])\n",
      "Label: tensor([45,  5,  1, 54, 66, 50, 39, 32, 46, 27, 56,  4, 32,  6,  0, 32])\n",
      "Label: tensor([47, 72, 57, 54,  3, 63, 71, 21, 55, 34, 57, 20, 61, 66, 29, 52])\n",
      "Label: tensor([40, 34, 19, 58, 67, 14, 52, 47, 49,  6, 18, 34,  3, 14, 20, 14])\n",
      "Label: tensor([50, 48, 55, 36, 10, 71, 36,  3, 10, 62,  8, 66, 24, 66, 47, 38])\n",
      "Label: tensor([ 2, 14, 43,  2, 24, 64, 61, 19, 27, 65, 46, 57, 54, 24, 51,  2])\n",
      "Label: tensor([46,  1, 14,  5, 22,  3, 17, 30, 37, 12, 14, 69,  8, 60, 49, 56])\n",
      "Label: tensor([23, 67, 64, 43,  7, 16, 39, 34,  7, 51, 58, 32, 30, 56, 68, 18])\n",
      "Label: tensor([ 8, 67, 67, 14, 61, 71, 61, 48, 54, 62, 56, 39, 17,  9, 60, 15])\n",
      "Label: tensor([13, 24, 17, 30, 58, 30, 24, 65, 31, 30,  5, 12, 71,  8, 16, 20])\n",
      "Label: tensor([57, 19, 21, 60, 39, 18, 51, 47, 50, 65, 22, 10, 36,  5, 25, 14])\n",
      "Label: tensor([12, 30, 36, 24, 56, 15, 30, 45, 26,  6, 11, 11, 58, 12, 53,  0])\n",
      "Label: tensor([ 0,  6, 15, 61, 57, 35, 55, 59, 44, 11, 18, 12, 48, 12, 19, 46])\n",
      "Label: tensor([ 9, 18, 45, 22, 18,  9, 29,  6,  9, 17, 27, 45, 55, 22, 65, 53])\n",
      "Label: tensor([55, 64, 62, 25, 69, 56, 25, 49, 19, 58, 39, 15, 48, 65, 62, 67])\n",
      "Label: tensor([68, 48,  9, 61, 26, 21, 36, 40, 10, 61, 16, 56, 54,  7, 22, 32])\n",
      "Label: tensor([ 7, 18, 45,  4, 20, 68, 65, 27, 67, 37, 70, 26, 53, 72, 24, 13])\n",
      "Label: tensor([15,  9, 72,  4, 71, 34, 58,  7, 25, 40, 21, 16, 64, 27, 29, 50])\n",
      "Label: tensor([48, 39,  6, 57, 38, 12,  9, 58, 72, 65, 11, 71, 55, 52, 22, 30])\n",
      "Label: tensor([44, 71, 67, 12, 47, 63, 51, 26, 43, 40,  3, 26, 59, 38,  6, 45])\n",
      "Label: tensor([67, 19, 37, 70, 70, 38,  5, 17, 35,  4, 41,  2, 17, 10, 57, 36])\n",
      "Label: tensor([53,  0, 24, 10, 29, 63, 24, 52, 64, 58,  0, 39, 68, 59, 47,  6])\n",
      "Label: tensor([50,  4, 32, 20, 19, 20,  8,  7, 22, 30, 34, 12, 62, 34, 23, 34])\n",
      "Label: tensor([43, 14, 71,  0,  2, 21, 40, 48, 43, 29, 48, 17, 31,  0, 46, 60])\n",
      "Label: tensor([29, 37, 11, 51, 17, 17, 50,  6, 16, 27, 11,  7, 70, 68, 26, 45])\n",
      "Label: tensor([68, 63, 10, 26, 72, 46, 45, 50, 54, 54, 24, 19, 50, 10, 60, 39])\n",
      "Label: tensor([ 6, 63, 62, 11, 31, 22,  3, 59, 49, 68, 21, 45,  7, 18, 33, 44])\n",
      "Label: tensor([55, 44,  2,  9,  8, 42, 49, 44, 24,  5, 52, 17, 69, 41, 39,  0])\n",
      "Label: tensor([53, 46,  4, 56, 44, 50, 67, 19, 38, 71, 31, 59, 23, 25, 37, 30])\n",
      "Label: tensor([61, 45, 17, 34, 64, 63, 34, 24, 28, 14, 67, 67, 50, 43, 43, 56])\n",
      "Label: tensor([44, 60, 25,  1, 56,  7, 48, 38, 63, 23,  3, 50, 38, 49,  5, 48])\n",
      "Label: tensor([34, 57, 71, 30, 18, 22,  7, 16, 60,  0, 10, 49, 24, 12, 61, 54])\n",
      "Label: tensor([60, 32, 49, 62, 49, 43, 57, 59, 59, 70, 42, 69, 21, 14, 50, 36])\n",
      "Label: tensor([42, 23, 72,  7, 41, 59, 49, 20, 49, 36, 51, 70, 50,  2, 20, 44])\n",
      "Label: tensor([63, 24, 14, 28, 63, 58, 66,  3, 60, 30, 25, 54, 64, 20, 32, 34])\n",
      "Label: tensor([46, 13, 54, 45, 25,  9, 22, 19, 66, 35, 47, 46, 53, 18, 59, 37])\n",
      "Label: tensor([22, 65, 51, 31, 65, 11, 11, 71, 62, 54, 40, 10, 33, 22, 50, 36])\n",
      "Label: tensor([51, 27, 58, 44, 40, 17, 43, 29, 25, 38, 11, 55, 16, 56,  1, 11])\n",
      "Label: tensor([29, 62, 45, 22, 70, 69, 14, 56, 52, 37, 51, 68, 49, 33, 39,  2])\n",
      "Label: tensor([51, 68, 35,  6, 32, 46, 55, 64, 11, 65, 51, 72, 10, 44, 38, 43])\n",
      "Label: tensor([57,  8, 52, 23, 57, 18,  0, 52, 24, 21, 29, 53, 32, 28, 29, 45])\n",
      "Label: tensor([63, 32, 69, 15, 65, 69, 35,  1,  6, 62,  0, 65, 34, 69, 32, 43])\n",
      "Label: tensor([ 7, 11, 36, 46, 46, 55, 20, 38,  2,  6, 52,  7, 53, 72, 20, 58])\n",
      "Label: tensor([22, 54, 63,  0, 59, 47, 30,  2, 68, 60, 18, 44, 49, 62, 13, 37])\n",
      "Label: tensor([20, 62, 47, 15, 49, 31,  1, 23, 72, 69, 36, 70, 33, 14, 46, 27])\n",
      "Label: tensor([65, 64, 45,  0,  1,  5, 48,  9, 66, 61, 29, 11, 61, 15, 21, 64])\n",
      "Label: tensor([45, 67, 12,  8, 53,  1, 70,  3, 18, 64, 67, 38, 37,  7, 42,  2])\n",
      "Label: tensor([45,  0, 50, 67, 67,  2, 18, 19, 50, 52,  9, 32, 11, 62, 68, 39])\n",
      "Label: tensor([ 2, 61, 70, 51, 62, 13, 24,  8, 21, 51, 35, 44, 51, 50, 31, 61])\n",
      "Label: tensor([60, 63, 50, 16, 43,  4, 47, 19, 45, 25,  6, 27, 27, 59, 40, 44])\n",
      "Label: tensor([57, 30, 30, 57, 70, 27, 54, 10, 52, 58, 42, 72,  7, 14, 62, 64])\n",
      "Label: tensor([13, 10,  8, 12, 38, 70, 37, 44, 69, 20, 60, 12, 58, 54, 53,  4])\n",
      "Label: tensor([40, 68, 15, 55, 53, 16, 32, 44,  6, 47, 14, 34,  3, 17, 36, 72])\n",
      "Label: tensor([61, 65, 49, 69, 47, 36, 10, 48, 12, 44, 16, 16, 47, 13,  0, 23])\n",
      "Label: tensor([71, 46, 10, 10, 61,  2, 63, 10,  0, 56, 53,  6,  6, 11, 70, 11])\n",
      "Label: tensor([ 0, 59, 32, 11, 55, 35, 14,  1, 10, 14, 57, 63, 48, 67, 26, 71])\n",
      "Label: tensor([15, 16, 32, 23, 47, 64,  6, 21, 20, 58, 13,  3, 28, 49, 65, 54])\n",
      "Label: tensor([58, 24, 70, 34, 30, 59,  1, 33, 59, 29, 67,  8, 31, 14, 22, 52])\n",
      "Label: tensor([23,  6, 23, 15, 38, 57, 59, 61, 54, 10,  2, 60, 52, 30, 11, 24])\n",
      "Label: tensor([45, 26, 45, 44, 26, 12, 19, 17, 68, 43,  3, 21, 42, 32, 45, 21])\n",
      "Label: tensor([66, 26, 11, 44, 52,  0,  8, 58,  1, 20,  1, 32,  6,  4, 63, 16])\n",
      "Label: tensor([42, 51,  6, 27,  9,  3,  1, 38, 52,  8, 24, 40, 34, 56, 38, 46])\n",
      "Label: tensor([37, 51, 66, 60, 16,  7, 55, 16, 25, 45, 39, 59, 42, 36, 62, 11])\n",
      "Label: tensor([32, 51,  7, 32, 33, 49, 53, 63, 29, 56, 72, 40, 22, 29, 22, 47])\n",
      "Label: tensor([38, 20, 63, 34, 17, 39, 35, 46, 53, 71, 10, 53, 21, 12, 23, 61])\n",
      "Label: tensor([62, 45, 63, 51, 11, 38, 59, 14, 11, 30, 10, 65,  6, 66, 11, 65])\n",
      "Label: tensor([ 1, 37, 30, 63,  8, 57,  0, 26, 31, 64, 39, 63, 31, 72, 29, 11])\n",
      "Label: tensor([68, 43, 50, 26, 24, 12, 31, 45, 48, 65, 53, 50, 48, 62, 42,  9])\n",
      "Label: tensor([27, 58, 57,  8, 56, 62, 65, 49, 57, 12, 37, 24, 54,  7,  6, 45])\n",
      "Label: tensor([62, 70, 32, 30, 65, 24,  5, 52,  2,  3,  0, 49, 30, 67, 63, 20])\n",
      "Label: tensor([17, 57, 10, 64, 57, 29, 55, 24, 19, 27, 38, 15, 68, 47, 10, 15])\n",
      "Label: tensor([40, 46, 45, 69, 22, 16, 35, 70, 31, 30, 54, 41, 14, 24, 70, 12])\n",
      "Label: tensor([65, 56,  2, 50, 54, 11, 30, 32, 30, 54, 30, 15, 33,  3,  4,  6])\n",
      "Label: tensor([64,  8, 37, 32, 19,  4, 70,  1, 41, 24, 71, 11,  7, 16, 45, 44])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([38, 41, 36, 33, 66, 34, 37, 47, 43, 37,  7,  2, 21, 64, 23, 63])\n",
      "Label: tensor([26,  6, 63, 45, 20, 61, 46, 46, 63, 26, 10, 15, 63, 26, 15, 21])\n",
      "Label: tensor([21,  6, 19, 67, 22, 15,  3,  3, 37, 15, 68,  7, 56, 62,  6,  5])\n",
      "Label: tensor([61, 44, 40, 70, 10, 22, 20, 52, 22, 29, 60, 71, 17, 38, 66, 62])\n",
      "Label: tensor([10, 66, 52,  5,  7, 66, 34, 30,  9, 70, 21, 20, 19, 50, 61, 56])\n",
      "Label: tensor([ 1, 53, 44, 61, 58, 65, 17, 46, 48, 34, 46, 52, 61, 42, 25, 20])\n",
      "Label: tensor([ 5, 51,  0, 40, 26, 47, 31, 50, 49, 23,  9, 58, 10, 31,  5,  8])\n",
      "Label: tensor([ 3, 24, 24, 51,  4, 61, 43, 31,  7, 22, 17, 66, 33, 27,  3, 63])\n",
      "Label: tensor([ 0, 62,  7,  3, 43, 11,  6, 19, 32, 42, 72, 23, 35, 50,  5, 34])\n",
      "Label: tensor([64, 49, 60, 46, 22, 64, 15, 47,  9, 10,  8, 36, 49, 19, 22,  0])\n",
      "Label: tensor([20, 56, 63, 46, 56, 40, 31, 41, 33, 42, 71, 29,  5, 36, 46, 52])\n",
      "Label: tensor([41, 66, 55, 32, 17, 47, 33, 70, 21, 39, 14, 26, 33, 42, 13, 16])\n",
      "Label: tensor([43, 57, 13,  7, 11,  2, 30,  9, 68, 23, 68,  7, 24, 62, 65,  6])\n",
      "Label: tensor([45, 43, 67, 68, 57, 71,  9, 12, 15, 34, 17, 24, 68, 70, 62, 13])\n",
      "Label: tensor([ 8, 24, 10,  0, 64, 63, 38,  0, 20, 12, 70, 62, 33, 20, 63, 69])\n",
      "Label: tensor([63, 46, 43,  7, 33, 61, 66, 59, 16, 44, 27,  4, 24, 54, 62, 38])\n",
      "Label: tensor([15, 10, 37, 72, 35, 19, 11, 66, 16, 15,  7, 66, 49, 59, 52, 61])\n",
      "Label: tensor([42, 68, 53, 38, 45, 72, 38, 22, 52, 66,  9,  5, 62, 19,  8, 54])\n",
      "Label: tensor([37,  6, 47, 37, 60,  4,  2, 50, 58, 61, 62,  4, 12, 51, 48, 64])\n",
      "Label: tensor([65, 39, 65, 49, 61, 29, 45, 14, 43, 61, 60, 39, 29, 23, 71, 45])\n",
      "Label: tensor([29, 57, 23, 19, 46, 49, 22, 51, 32, 68, 71, 26, 69, 47, 20, 45])\n",
      "Label: tensor([15, 14, 63, 21, 50, 38, 22, 57, 20, 18, 53, 31,  3, 16,  5, 20])\n",
      "Label: tensor([65, 49, 27, 39,  8,  9, 19, 68, 19, 62, 25,  5, 20,  9,  9, 63])\n",
      "Label: tensor([ 4,  5,  6, 58, 18, 40, 49, 15, 12, 40, 65, 44, 70, 24,  7, 57])\n",
      "Label: tensor([17, 46, 51, 45, 16, 23, 71, 10, 62, 40, 53, 14, 42,  4, 45,  6])\n",
      "Label: tensor([27, 16, 40, 24, 40, 66, 21,  6, 32, 36, 51, 38, 60, 63, 11, 68])\n",
      "Label: tensor([69, 24,  5, 64, 39, 50, 24,  6, 21,  8, 38, 53, 30, 36,  4, 40])\n",
      "Label: tensor([71, 63, 49, 67, 12, 22, 24, 66,  4, 47, 15, 54, 33, 36, 29, 70])\n",
      "Label: tensor([29, 39, 65, 49,  8, 32, 65, 67, 32,  4,  6,  4, 66, 61, 15, 32])\n",
      "Label: tensor([51, 43,  5, 49, 56, 24,  1, 48,  2, 29, 54, 35, 38, 72, 70, 16])\n",
      "Label: tensor([43, 71, 45, 50, 21, 38, 47, 65, 31, 66,  5,  8, 48, 67, 45, 23])\n",
      "Label: tensor([43, 43, 59,  5, 61, 40, 13, 55, 42, 14, 16, 15, 64, 49,  4, 25])\n",
      "Label: tensor([24,  6, 57, 31, 18, 26, 67, 67, 69, 30, 24, 12,  9, 10, 64,  2])\n",
      "Label: tensor([43, 70, 30, 11, 55, 23, 22, 42, 53, 63, 58,  7,  5, 69, 32, 34])\n",
      "Label: tensor([45, 35, 19,  0, 12, 14,  8, 63, 32, 38, 71, 10, 70, 43, 63, 42])\n",
      "Label: tensor([11, 13, 50, 65, 56, 23, 68, 59, 32, 11,  6,  2, 31, 70, 62, 24])\n",
      "Label: tensor([55, 49, 11, 54, 22, 25,  8, 35, 16, 57, 16, 65,  4, 49, 42,  5])\n",
      "Label: tensor([65,  8, 67, 42, 32, 58, 34, 47, 13, 11, 42, 68, 26,  4, 32, 37])\n",
      "Label: tensor([71, 49,  7, 17, 61, 53, 20, 52, 45, 49,  6,  6, 57, 32, 45, 31])\n",
      "Label: tensor([ 0, 20,  7, 17, 37,  5, 14, 71, 17, 63, 64, 67, 59,  1, 53, 50])\n",
      "Label: tensor([42, 62,  4, 10,  2, 55, 26, 45, 39, 29, 71, 36, 51, 50, 65, 24])\n",
      "Label: tensor([38, 27, 33, 50, 59,  5, 12, 49, 26, 10, 51, 45, 37, 58, 22,  5])\n",
      "Label: tensor([22, 43, 18, 46, 54,  4, 10, 46, 51, 44, 37, 68, 47, 44,  7, 11])\n",
      "Label: tensor([72, 35, 55, 18, 50, 72, 10, 47, 71,  4,  5, 49,  8, 72, 39, 18])\n",
      "Label: tensor([39, 14,  5, 49, 54,  9, 56, 12,  0, 20,  9, 61, 17, 19, 48, 39])\n",
      "Label: tensor([25, 56, 32, 39, 34, 30, 58,  5, 64, 46,  0, 25, 18, 67, 48, 37])\n",
      "Label: tensor([15, 56, 19, 13, 17, 25, 64, 47, 54, 27,  7, 17, 33, 10, 38,  4])\n",
      "Label: tensor([25, 33, 34,  8, 70, 37, 36, 63, 72, 62, 47, 55, 41, 31, 42,  5])\n",
      "Label: tensor([56,  9, 58, 72, 58,  5, 67, 27, 60, 63, 39, 34, 35, 64, 24, 35])\n",
      "Label: tensor([17, 22, 62, 14, 32, 26, 12, 39, 69, 71, 14, 54, 51, 23, 11, 29])\n",
      "Label: tensor([14,  7,  5, 69, 24, 57,  9, 36,  5, 25, 23, 33, 34, 67, 24, 38])\n",
      "Label: tensor([66,  6, 49, 45, 53, 45, 63,  4, 14, 40, 30,  7, 54, 27, 37, 25])\n",
      "Label: tensor([30, 34, 65, 58,  8, 60, 32, 11, 16, 44,  2, 53, 63, 46,  4, 31])\n",
      "Label: tensor([37, 26, 17,  7, 70, 70, 56, 60, 70, 17, 62,  6, 55, 37, 25, 24])\n",
      "Label: tensor([42, 22, 44, 23,  5, 66, 22, 40, 24, 68, 40,  9, 42, 32, 48, 38])\n",
      "Label: tensor([ 9, 66,  7, 66,  8, 21, 57, 66, 69, 34, 55, 46, 31,  6, 63,  1])\n",
      "Label: tensor([15, 34, 66, 11, 16, 18, 26, 20, 55, 22,  6, 52, 63, 52, 69, 62])\n",
      "Label: tensor([45, 20, 46, 45, 47, 60, 54, 14, 45, 19,  9, 38, 26, 34, 36, 62])\n",
      "Label: tensor([39, 66, 47, 67,  6,  9,  6, 22, 27, 53, 33, 12, 18, 65, 11,  8])\n",
      "Label: tensor([13, 39, 21, 67, 49, 72, 14, 29, 60, 39, 72, 37,  1, 44, 52,  4])\n",
      "Label: tensor([58, 46, 33,  1, 52, 42, 61, 65, 17, 62, 70, 62, 68, 20, 40, 18])\n",
      "Label: tensor([24, 47, 51, 19, 54, 72, 39, 37, 51, 45, 17, 11, 49, 70, 12, 18])\n",
      "Label: tensor([59, 68,  7, 50, 54, 58, 63, 44,  3, 26, 20, 15, 54,  2, 69, 61])\n",
      "Label: tensor([64, 50, 34,  8, 18, 23, 46, 61, 71, 24, 45, 15, 10, 51, 18, 18])\n",
      "Label: tensor([63, 59, 56,  0,  9, 58, 30, 54, 62, 22, 47, 54, 67, 11, 13, 51])\n",
      "Label: tensor([37, 26,  1, 23, 26,  2, 24, 12, 65, 65, 12, 23, 69,  5, 60, 68])\n",
      "Label: tensor([19, 48, 27, 42, 64, 61, 65, 65, 47, 36, 35,  0, 63, 63, 11, 24])\n",
      "Label: tensor([62, 54, 37, 60, 22, 46, 32, 32, 34,  0, 42, 13, 68, 10, 14, 65])\n",
      "Label: tensor([ 6, 27, 53, 50, 27,  9, 52, 72, 38, 59, 54, 42, 16, 12, 34, 72])\n",
      "Label: tensor([42, 18, 47, 43, 30, 25, 57,  0, 55, 51, 37, 26, 23, 21, 34, 54])\n",
      "Label: tensor([53, 36,  5, 59, 17,  8, 19, 16, 58, 32, 26,  2,  9, 69, 68, 53])\n",
      "Label: tensor([16,  7, 12, 70, 11, 57, 45, 69, 17, 46, 67, 26, 24, 49, 72, 54])\n",
      "Label: tensor([46,  4, 36, 18, 12, 17, 45, 68, 34, 18, 70, 16, 26, 64, 58, 24])\n",
      "Label: tensor([59, 49, 12,  9, 72, 41, 27, 14, 61, 60, 66,  8, 55, 36,  5, 22])\n",
      "Label: tensor([22,  2, 26, 48, 57, 29, 59, 70, 52, 18, 51, 25, 43, 57, 23, 48])\n",
      "Label: tensor([17, 34, 19, 54, 38,  4, 19, 32,  4, 54, 42, 61, 49, 63, 17, 27])\n",
      "Label: tensor([46, 60, 53, 45, 45, 37, 20, 23, 34, 14, 40, 17, 57,  6, 67, 64])\n",
      "Label: tensor([70, 60, 63, 59, 19, 24, 70, 30, 17, 65, 35, 13,  1, 51, 13, 72])\n",
      "Label: tensor([ 4, 30, 32,  3,  8, 30, 64,  3, 65, 63, 25, 65, 59, 33, 38, 30])\n",
      "Label: tensor([36, 67, 11, 17, 15, 27, 70,  5,  7, 24, 48, 15, 52, 58,  6, 17])\n",
      "Label: tensor([31, 20, 71, 25, 23, 15, 55, 38, 13, 26, 54,  5, 63, 68, 23,  7])\n",
      "Label: tensor([29, 67, 45, 49, 24, 59, 24, 66, 28, 55, 38, 42,  3, 45, 11, 56])\n",
      "Label: tensor([16, 17,  1, 49,  9, 22, 12, 13,  9, 36,  5, 32,  1, 69,  5, 42])\n",
      "Label: tensor([29, 13, 38, 30, 57, 64, 44,  2, 32, 37,  7, 27, 68, 58,  1, 64])\n",
      "Label: tensor([45, 26, 15, 16, 59, 15, 36, 65, 51, 57,  3, 59, 63, 66, 51, 68])\n",
      "Label: tensor([17, 21, 70, 52, 34, 40, 68, 33, 30, 15, 49, 19, 70, 49,  5, 70])\n",
      "Label: tensor([37, 63, 21, 26, 61, 34, 23, 62, 17,  9, 37, 26, 12, 23, 36, 47])\n",
      "Label: tensor([16, 17,  8, 68,  3,  4, 35, 63, 56, 58, 27, 50, 61, 64, 40, 33])\n",
      "Label: tensor([ 6, 26, 49, 72, 18, 39,  0, 52, 62, 69, 51, 33, 14, 48, 29, 59])\n",
      "Label: tensor([34, 71,  2, 40, 72, 49, 38, 27, 19, 22, 20,  3, 16, 14,  3, 42])\n",
      "Label: tensor([61, 63, 30,  4, 58, 65, 58, 21, 19,  2, 53, 65, 65, 55, 64, 49])\n",
      "Label: tensor([65,  0, 18, 18, 15, 45, 21, 53, 42,  6, 10, 39, 21, 21, 64, 71])\n",
      "Label: tensor([17, 11, 72, 30, 48, 53, 31, 27, 68, 57, 15, 15, 32, 45,  9,  3])\n",
      "Label: tensor([ 6, 65, 65, 47, 39, 71, 63, 19, 22, 27, 10, 22, 20, 27,  9, 38])\n",
      "Label: tensor([56, 28,  4, 63, 61, 14, 42, 55, 57, 10, 70, 58,  4, 32, 20, 67])\n",
      "Label: tensor([56, 19, 29, 10, 23, 35, 50, 32, 39,  6, 65,  0,  9, 18, 17, 67])\n",
      "Label: tensor([63, 71, 18, 14, 67, 37, 12, 59, 63, 37, 58, 10, 27, 31, 53, 12])\n",
      "Label: tensor([26, 69, 27, 43, 26, 40,  1, 72, 39, 12, 48, 23, 65, 71, 20, 45])\n",
      "Label: tensor([58, 17, 41, 54, 45, 24, 66, 21, 48, 64, 42, 37, 25, 66, 31, 30])\n",
      "Label: tensor([38, 60, 38, 70, 63, 24, 21, 12, 70, 61, 59, 37, 32, 11, 27, 40])\n",
      "Label: tensor([26,  5, 70, 61,  6, 23, 15, 29, 26, 42,  1, 16, 66, 48, 54, 65])\n",
      "Label: tensor([22, 53, 30, 50, 44, 16, 47,  5, 68,  2, 72, 69, 51, 26, 51, 55])\n",
      "Label: tensor([51, 33, 26, 36, 44, 10,  9,  0, 26, 35, 41, 43, 61, 11, 12, 49])\n",
      "Label: tensor([50, 29, 34, 57, 49, 40,  7, 62, 31, 26, 43, 18, 52, 59, 31, 55])\n",
      "Label: tensor([13, 70, 53, 36,  9,  8, 59, 14, 52, 25,  4, 35,  0,  2, 22, 42])\n",
      "Label: tensor([57, 23, 38, 56, 56, 11, 45, 59, 66, 26, 59, 24, 48, 50, 21,  2])\n",
      "Label: tensor([49,  3, 66, 11, 46,  1, 36, 64, 26,  7, 56, 45, 10, 24, 26, 51])\n",
      "Label: tensor([58, 60, 35, 51, 66,  4, 22,  3, 19,  2,  2, 21, 11, 63, 56,  6])\n",
      "Label: tensor([44, 38, 68, 49, 55, 30, 67,  9, 62, 72, 39, 71, 67, 70,  0, 60])\n",
      "Label: tensor([23, 63, 57, 33, 48,  9, 12, 70, 57, 29, 40, 46, 27, 61, 65, 40])\n",
      "Label: tensor([39, 11, 47,  9, 70, 62, 11, 62, 17,  8, 53, 53,  7,  9, 52, 70])\n",
      "Label: tensor([39, 40, 14,  2, 16, 46, 14, 67, 35,  5,  7, 55,  3, 27, 64, 25])\n",
      "Label: tensor([48, 38, 16, 59, 41, 44,  3, 57, 56, 12, 19, 14, 37, 72, 22, 31])\n",
      "Label: tensor([ 9, 66, 60, 61, 54, 55, 32, 60, 37,  7, 51, 23, 42,  6,  8, 32])\n",
      "Label: tensor([66, 68,  5, 72, 57, 50, 21, 13,  7, 17, 72, 16, 48, 45, 33, 14])\n",
      "Label: tensor([53, 11, 57, 43, 46, 55, 22, 45,  2, 68, 64, 37, 72, 20, 34, 51])\n",
      "Label: tensor([12, 41,  3,  8, 30, 58, 19, 72, 59, 29, 36,  3, 17, 50, 32, 26])\n",
      "Label: tensor([30, 22, 66, 66, 30,  5, 16, 60, 31, 63, 57, 70, 58, 22, 62, 52])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([57, 47, 22, 31, 57, 31, 54, 53, 52,  8, 27, 13, 20, 53, 24, 39])\n",
      "Label: tensor([49, 46, 11,  5, 25, 46, 62,  0, 17, 27, 37, 50, 13, 54, 48,  7])\n",
      "Label: tensor([56, 70,  4,  0, 65, 69, 32,  1, 65, 58, 10,  9, 21, 68,  9, 17])\n",
      "Label: tensor([34, 52,  9, 50, 47,  2, 24, 16, 47, 26,  0, 26, 70, 30, 33, 35])\n",
      "Label: tensor([15, 30, 38, 51,  4,  7,  5, 38, 34, 17,  7,  2, 47, 14, 67,  3])\n",
      "Label: tensor([59, 47, 71, 55,  9, 27,  4, 12, 51, 31, 65,  2, 19, 69, 51, 67])\n",
      "Label: tensor([62, 59,  6, 32, 65, 32, 31, 54, 52, 51,  7, 67, 34, 34, 36, 64])\n",
      "Label: tensor([51, 61, 19, 12, 36, 32, 14, 12, 57, 35, 50, 72, 64, 38, 30, 60])\n",
      "Label: tensor([20, 48, 64, 64, 12, 47, 44, 13, 56, 21, 32, 19, 69, 20, 69, 52])\n",
      "Label: tensor([18, 70, 31, 38, 40, 56, 19, 52,  4,  4, 16, 50, 18, 57,  6, 33])\n",
      "Label: tensor([16, 31, 46,  1,  1, 21, 35, 34, 48, 25, 57, 42, 16, 27,  1,  0])\n",
      "Label: tensor([51, 58, 57,  2, 29, 30,  8, 14,  7, 32, 70, 39,  8,  3,  1, 23])\n",
      "Label: tensor([21,  4, 39, 39, 17, 12, 49, 26, 58, 29, 23, 38, 54, 61, 18,  0])\n",
      "Label: tensor([32, 35, 60, 25,  2, 55, 14, 18, 35, 38, 43, 62,  5, 29, 56, 36])\n",
      "Label: tensor([20, 10, 10,  1, 64, 61, 72, 45, 26, 63, 67,  5, 41,  0, 23, 30])\n",
      "Label: tensor([66, 69,  1, 61, 72, 17, 21, 35, 32, 29, 60, 52,  6, 24, 14, 22])\n",
      "Label: tensor([60, 27, 34, 44,  9, 31, 45, 15, 32, 24,  2, 24, 16, 37, 24, 42])\n",
      "Label: tensor([ 7, 67, 66, 70, 13, 52, 29,  0, 60, 50, 42,  5, 36, 50, 64, 17])\n",
      "Label: tensor([69,  3, 17,  5, 11, 11, 10, 54, 37, 20, 47, 65, 66, 55, 61, 64])\n",
      "Label: tensor([ 0, 10, 61, 59, 35, 15, 63, 61, 61, 45, 31, 54, 20, 42, 61, 70])\n",
      "Label: tensor([11, 24, 24, 64, 20, 42, 21,  2, 32, 21, 64, 48, 32, 13, 69, 26])\n",
      "Label: tensor([ 6,  9, 45, 66, 39, 59, 49, 25, 30, 40, 14, 26, 56, 44, 55,  6])\n",
      "Label: tensor([ 9,  4, 43, 37, 42,  1, 12, 52, 33, 40, 13, 18, 35, 18, 45,  2])\n",
      "Label: tensor([72, 67, 27, 33, 65, 69, 40, 32, 33, 49, 18, 27, 30, 16, 51, 69])\n",
      "Label: tensor([32,  9, 20, 37, 26, 30, 64, 33, 55, 40, 39, 11, 62, 48, 33, 63])\n",
      "Label: tensor([36, 16,  5, 55, 27, 38, 35, 13, 47,  7, 38, 56,  9, 51, 65, 19])\n",
      "Label: tensor([ 7, 55,  0, 27, 24, 12,  7,  0, 36, 31, 29, 58, 29, 44, 62, 29])\n",
      "Label: tensor([63, 66, 48, 22, 55,  1, 32, 66,  2, 14, 56, 63, 18, 12, 15, 66])\n",
      "Label: tensor([45, 58, 19, 26, 27, 49, 14, 44, 52, 45, 32, 50, 20, 54, 36, 42])\n",
      "Label: tensor([14,  3, 55, 49, 34,  6, 45,  7, 51, 63, 12, 51, 72,  1, 43,  1])\n",
      "Label: tensor([ 3, 58, 11, 45, 20,  7, 49, 54, 12,  6, 63, 24, 36, 62, 24, 46])\n",
      "Label: tensor([45, 72, 64,  1, 36, 41, 40,  9, 64, 21, 16,  6, 10, 14, 40, 31])\n",
      "Label: tensor([51, 25, 46,  1, 24, 16, 26,  7, 22, 15, 44, 57, 44, 43, 37, 51])\n",
      "Label: tensor([11, 54, 32, 21,  2, 62, 47, 29, 31, 52,  2,  0, 67, 35, 16,  2])\n",
      "Label: tensor([12,  9, 62, 20, 62, 60, 47,  3, 28, 29, 44, 15, 72,  3, 66, 68])\n",
      "Label: tensor([30, 51, 38, 42,  3, 12,  4, 29, 23, 32, 47, 22, 14, 43, 50, 47])\n",
      "Label: tensor([35, 55, 24,  3, 22, 57,  0, 63, 71, 38, 69, 24,  8, 62,  1, 15])\n",
      "Label: tensor([24, 54, 64,  2, 38, 33, 61, 38, 54, 38, 36, 14, 70, 14, 19, 29])\n",
      "Label: tensor([11,  3, 59, 57, 39, 66, 42, 61, 26, 69, 10, 70,  7, 24, 31, 36])\n",
      "Label: tensor([25, 27, 64, 24, 34,  6,  5, 23, 63, 53, 42, 42, 11, 35, 26, 56])\n",
      "Label: tensor([54, 52, 58,  8, 64, 23, 29, 54, 25, 63, 64, 27, 19, 65, 11,  5])\n",
      "Label: tensor([71, 37, 38, 11, 26, 71, 52, 25,  0, 10, 22, 36, 70, 30, 68,  3])\n",
      "Label: tensor([24, 12, 44, 63, 53,  5, 29, 48, 38, 46, 66, 66, 39, 43,  4,  5])\n",
      "Label: tensor([ 2, 15, 70, 67, 63, 49, 72, 45, 70, 49, 56, 34, 22, 14, 32, 24])\n",
      "Label: tensor([45, 25, 42, 39, 44, 30, 61, 28, 16,  2, 17, 38, 52, 45,  3, 23])\n",
      "Label: tensor([26, 70, 36, 18, 17, 44, 15, 18, 15,  4, 48, 31, 38, 69, 65, 34])\n",
      "Label: tensor([34, 14, 34, 68, 53,  2, 44, 26, 27, 47, 72, 69,  9,  8,  7,  6])\n",
      "Label: tensor([68,  5, 27, 24, 26, 36, 20, 39, 10, 52, 70, 37,  2, 39,  7, 40])\n",
      "Label: tensor([55, 57, 26, 51, 58, 17, 50, 30, 16, 22,  4,  9, 30, 46, 56, 30])\n",
      "Label: tensor([19, 47, 27, 51,  4, 42, 46, 25, 44, 60,  8, 64, 72, 58, 30, 38])\n",
      "Label: tensor([40, 52, 70, 12, 53, 17, 18,  6, 18, 57, 36, 49, 53, 12, 64, 34])\n",
      "Label: tensor([58, 68, 58, 26, 67,  5, 57, 53, 30, 63, 29, 70,  6, 14, 68, 24])\n",
      "Label: tensor([61, 32, 32, 12, 42, 61, 32, 33, 66, 14, 12,  7, 50, 29, 49, 51])\n",
      "Label: tensor([56, 71,  0, 54,  3, 18, 54, 13, 39, 62, 22, 20, 42, 62, 15, 51])\n",
      "Label: tensor([31, 23, 55, 32, 53, 30, 20, 29, 55, 59, 45, 20, 53, 57, 69, 47])\n",
      "Label: tensor([10, 65, 49, 44, 31, 56, 12, 24, 51,  5, 59,  0, 59, 31,  1, 58])\n",
      "Label: tensor([61, 16, 17, 17, 71, 42, 13, 26, 68, 18, 50, 43, 54, 68, 30, 17])\n",
      "Label: tensor([ 5,  0, 11, 35, 21, 54, 57, 69, 66,  6, 40, 22, 58, 63, 31, 49])\n",
      "Label: tensor([51, 66, 34, 56, 24, 23, 46, 40,  4, 54, 21, 25,  3,  9,  1,  5])\n",
      "Label: tensor([32, 43, 38, 52, 18, 53, 14, 67, 31,  5, 14,  0, 63, 37, 39, 31])\n",
      "Label: tensor([19, 17, 62,  7, 23, 38, 52, 23, 11, 20, 13, 48, 23, 64,  0, 69])\n",
      "Label: tensor([38, 11, 44, 66, 67, 19, 14, 15, 30,  9,  4, 21,  9, 48, 13, 43])\n",
      "Label: tensor([20,  5, 51, 18,  6, 71, 17, 36,  5, 55, 66, 15, 53, 53, 17, 31])\n",
      "Label: tensor([ 3, 12, 33, 30, 13, 22, 48, 12, 49, 56, 57, 69,  4,  4, 15,  4])\n",
      "Label: tensor([23, 25, 38, 46, 71, 42, 70, 23, 30, 58, 19, 42, 55, 42, 46, 13])\n",
      "Label: tensor([41, 45, 55, 29, 65, 36, 58, 49, 24, 27, 14, 33, 20, 49, 40, 21])\n",
      "Label: tensor([59, 46, 17,  0, 32, 10, 65,  4, 24, 19, 33,  3, 15, 50, 55,  2])\n",
      "Label: tensor([49, 69, 54, 24, 45,  8, 37, 15, 40, 53, 71, 30, 57, 32, 64, 37])\n",
      "Label: tensor([70, 50, 68, 53, 31, 57, 45, 49, 70, 63,  0, 51, 70, 67, 51, 70])\n",
      "Label: tensor([55, 71, 58, 24, 52, 55, 66, 39, 70, 39,  0,  7,  1, 31,  9, 54])\n",
      "Label: tensor([70, 37, 16, 69,  9, 58, 37,  2, 32,  4, 57, 32, 15, 62, 62, 49])\n",
      "Label: tensor([33, 25, 54,  2, 43, 36,  5,  6, 16, 52, 56,  6, 24, 70, 29,  9])\n",
      "Label: tensor([59, 44, 42, 47,  3, 42,  1, 53, 57,  8, 45, 71, 69, 34, 58, 53])\n",
      "Label: tensor([30, 23,  9, 61, 53, 68, 10, 57, 44, 30, 33, 63, 19, 54, 38, 27])\n",
      "Label: tensor([40, 56, 32, 36, 59, 57, 15, 14,  8, 22,  2, 49, 50, 24, 64, 64])\n",
      "Label: tensor([15, 36, 29,  5, 14, 61, 11,  1,  4, 50, 62, 49, 50, 12, 53, 33])\n",
      "Label: tensor([62, 61, 54, 60,  9, 64, 56,  3, 56,  2,  9, 49, 15, 49, 71, 10])\n",
      "Label: tensor([29, 66,  9, 15, 61,  8, 67,  5, 43, 33, 42, 33, 66, 45, 56, 70])\n",
      "Label: tensor([54, 58, 32, 67, 40, 62, 33, 46, 51, 53, 27, 59, 72, 43,  4, 72])\n",
      "Label: tensor([56, 23, 60, 59, 40, 50, 12, 55, 20, 60, 19,  1, 48, 66, 27, 71])\n",
      "Label: tensor([35,  7, 20, 58, 34, 55, 47, 43, 38, 11, 21, 37, 15, 37, 18, 11])\n",
      "Label: tensor([ 5,  9, 20,  6, 24, 11, 48, 63, 34, 48, 61, 48, 12, 49, 69, 32])\n",
      "Label: tensor([29, 40, 21, 40, 35, 38, 36,  3, 32, 54, 48, 44, 16, 12,  9,  6])\n",
      "Label: tensor([26, 39, 20, 69, 11, 47,  6, 10, 23, 52, 53, 54, 31,  2, 57,  0])\n",
      "Label: tensor([68, 10, 66, 12, 53, 32, 13, 10, 65, 51,  6, 72, 14, 49, 10, 23])\n",
      "Label: tensor([31, 21, 65, 42, 46,  2, 57, 57, 16, 45, 45, 45, 33, 57, 21, 69])\n",
      "Label: tensor([21, 49, 68, 24, 64, 62,  2, 64, 38, 65,  0, 46,  4, 34, 20,  8])\n",
      "Label: tensor([67, 48, 72, 72, 46, 57, 45, 27,  8,  1, 27, 57, 52,  5, 71, 21])\n",
      "Label: tensor([ 7, 57,  8, 21, 40,  3, 33, 14,  2, 26, 10, 12, 65, 34, 39, 57])\n",
      "Label: tensor([35, 27, 10, 59, 67, 44,  1, 68, 51, 13,  3, 27, 59, 29, 55, 12])\n",
      "Label: tensor([24])\n"
     ]
    }
   ],
   "source": [
    "for image, label in trainloader:\n",
    "    print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Everything else from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv11): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv12): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (batch1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv21): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv22): Conv2d(40, 40, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (batch2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2560, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=73, bias=True)\n",
      "  (dropconv): Dropout(p=0.2, inplace=False)\n",
      "  (dropfc): Dropout(p=0.4, inplace=False)\n",
      "  (soft): Softmax(dim=1)\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: True\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "========================================BEGIN TRAINING=======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zacan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  [Epoch: 1, Batch: 10]   Train loss: 0.516  |  Test loss: 4.004  |  Test accuracy: 0.020  |\n",
      "|  [Epoch: 1, Batch: 20]   Train loss: 0.512  |  Test loss: 4.004  |  Test accuracy: 0.028  |\n",
      "|  [Epoch: 1, Batch: 30]   Train loss: 0.511  |  Test loss: 4.003  |  Test accuracy: 0.046  |\n",
      "|  [Epoch: 1, Batch: 40]   Train loss: 0.510  |  Test loss: 3.995  |  Test accuracy: 0.173  |\n",
      "|  [Epoch: 1, Batch: 50]   Train loss: 0.506  |  Test loss: 3.952  |  Test accuracy: 0.183  |\n",
      "|  [Epoch: 1, Batch: 60]   Train loss: 0.501  |  Test loss: 3.892  |  Test accuracy: 0.198  |\n",
      "|  [Epoch: 1, Batch: 70]   Train loss: 0.499  |  Test loss: 3.826  |  Test accuracy: 0.294  |\n",
      "|  [Epoch: 1, Batch: 80]   Train loss: 0.497  |  Test loss: 3.803  |  Test accuracy: 0.299  |\n",
      "|  [Epoch: 2, Batch: 10]   Train loss: 0.642  |  Test loss: 3.785  |  Test accuracy: 0.308  |\n",
      "|  [Epoch: 2, Batch: 20]   Train loss: 0.488  |  Test loss: 3.746  |  Test accuracy: 0.351  |\n",
      "|  [Epoch: 2, Batch: 30]   Train loss: 0.491  |  Test loss: 3.705  |  Test accuracy: 0.361  |\n",
      "|  [Epoch: 2, Batch: 40]   Train loss: 0.489  |  Test loss: 3.706  |  Test accuracy: 0.355  |\n",
      "|  [Epoch: 2, Batch: 50]   Train loss: 0.491  |  Test loss: 3.679  |  Test accuracy: 0.404  |\n",
      "|  [Epoch: 2, Batch: 60]   Train loss: 0.488  |  Test loss: 3.680  |  Test accuracy: 0.401  |\n",
      "|  [Epoch: 2, Batch: 70]   Train loss: 0.483  |  Test loss: 3.626  |  Test accuracy: 0.440  |\n",
      "|  [Epoch: 2, Batch: 80]   Train loss: 0.487  |  Test loss: 3.642  |  Test accuracy: 0.441  |\n",
      "|  [Epoch: 3, Batch: 10]   Train loss: 0.630  |  Test loss: 3.612  |  Test accuracy: 0.451  |\n",
      "|  [Epoch: 3, Batch: 20]   Train loss: 0.478  |  Test loss: 3.641  |  Test accuracy: 0.429  |\n",
      "|  [Epoch: 3, Batch: 30]   Train loss: 0.480  |  Test loss: 3.609  |  Test accuracy: 0.441  |\n",
      "|  [Epoch: 3, Batch: 40]   Train loss: 0.486  |  Test loss: 3.604  |  Test accuracy: 0.458  |\n",
      "|  [Epoch: 3, Batch: 50]   Train loss: 0.479  |  Test loss: 3.593  |  Test accuracy: 0.470  |\n",
      "|  [Epoch: 3, Batch: 60]   Train loss: 0.479  |  Test loss: 3.589  |  Test accuracy: 0.470  |\n",
      "|  [Epoch: 3, Batch: 70]   Train loss: 0.476  |  Test loss: 3.588  |  Test accuracy: 0.475  |\n",
      "|  [Epoch: 3, Batch: 80]   Train loss: 0.480  |  Test loss: 3.576  |  Test accuracy: 0.481  |\n",
      "|  [Epoch: 4, Batch: 10]   Train loss: 0.626  |  Test loss: 3.541  |  Test accuracy: 0.514  |\n",
      "|  [Epoch: 4, Batch: 20]   Train loss: 0.477  |  Test loss: 3.541  |  Test accuracy: 0.511  |\n",
      "|  [Epoch: 4, Batch: 30]   Train loss: 0.472  |  Test loss: 3.560  |  Test accuracy: 0.496  |\n",
      "|  [Epoch: 4, Batch: 40]   Train loss: 0.481  |  Test loss: 3.569  |  Test accuracy: 0.480  |\n",
      "|  [Epoch: 4, Batch: 50]   Train loss: 0.476  |  Test loss: 3.537  |  Test accuracy: 0.508  |\n",
      "|  [Epoch: 4, Batch: 60]   Train loss: 0.481  |  Test loss: 3.551  |  Test accuracy: 0.490  |\n",
      "|  [Epoch: 4, Batch: 70]   Train loss: 0.479  |  Test loss: 3.534  |  Test accuracy: 0.519  |\n",
      "|  [Epoch: 4, Batch: 80]   Train loss: 0.474  |  Test loss: 3.543  |  Test accuracy: 0.509  |\n",
      "|  [Epoch: 5, Batch: 10]   Train loss: 0.617  |  Test loss: 3.543  |  Test accuracy: 0.514  |\n",
      "|  [Epoch: 5, Batch: 20]   Train loss: 0.476  |  Test loss: 3.526  |  Test accuracy: 0.522  |\n",
      "|  [Epoch: 5, Batch: 30]   Train loss: 0.479  |  Test loss: 3.529  |  Test accuracy: 0.518  |\n",
      "|  [Epoch: 5, Batch: 40]   Train loss: 0.478  |  Test loss: 3.517  |  Test accuracy: 0.525  |\n",
      "|  [Epoch: 5, Batch: 50]   Train loss: 0.472  |  Test loss: 3.553  |  Test accuracy: 0.495  |\n",
      "|  [Epoch: 5, Batch: 60]   Train loss: 0.474  |  Test loss: 3.521  |  Test accuracy: 0.527  |\n",
      "|  [Epoch: 5, Batch: 70]   Train loss: 0.473  |  Test loss: 3.526  |  Test accuracy: 0.519  |\n",
      "|  [Epoch: 5, Batch: 80]   Train loss: 0.478  |  Test loss: 3.528  |  Test accuracy: 0.511  |\n",
      "|  [Epoch: 6, Batch: 10]   Train loss: 0.620  |  Test loss: 3.520  |  Test accuracy: 0.522  |\n",
      "|  [Epoch: 6, Batch: 20]   Train loss: 0.479  |  Test loss: 3.505  |  Test accuracy: 0.535  |\n",
      "|  [Epoch: 6, Batch: 30]   Train loss: 0.477  |  Test loss: 3.574  |  Test accuracy: 0.481  |\n",
      "|  [Epoch: 6, Batch: 40]   Train loss: 0.475  |  Test loss: 3.507  |  Test accuracy: 0.551  |\n",
      "|  [Epoch: 6, Batch: 50]   Train loss: 0.475  |  Test loss: 3.488  |  Test accuracy: 0.557  |\n",
      "|  [Epoch: 6, Batch: 60]   Train loss: 0.474  |  Test loss: 3.485  |  Test accuracy: 0.556  |\n",
      "|  [Epoch: 6, Batch: 70]   Train loss: 0.472  |  Test loss: 3.485  |  Test accuracy: 0.560  |\n",
      "|  [Epoch: 6, Batch: 80]   Train loss: 0.468  |  Test loss: 3.481  |  Test accuracy: 0.565  |\n",
      "|  [Epoch: 7, Batch: 10]   Train loss: 0.614  |  Test loss: 3.474  |  Test accuracy: 0.573  |\n",
      "|  [Epoch: 7, Batch: 20]   Train loss: 0.477  |  Test loss: 3.497  |  Test accuracy: 0.554  |\n",
      "|  [Epoch: 7, Batch: 30]   Train loss: 0.473  |  Test loss: 3.472  |  Test accuracy: 0.579  |\n",
      "|  [Epoch: 7, Batch: 40]   Train loss: 0.474  |  Test loss: 3.470  |  Test accuracy: 0.579  |\n",
      "|  [Epoch: 7, Batch: 50]   Train loss: 0.472  |  Test loss: 3.518  |  Test accuracy: 0.530  |\n",
      "|  [Epoch: 7, Batch: 60]   Train loss: 0.472  |  Test loss: 3.475  |  Test accuracy: 0.573  |\n",
      "|  [Epoch: 7, Batch: 70]   Train loss: 0.472  |  Test loss: 3.473  |  Test accuracy: 0.564  |\n",
      "|  [Epoch: 7, Batch: 80]   Train loss: 0.473  |  Test loss: 3.444  |  Test accuracy: 0.591  |\n",
      "|  [Epoch: 8, Batch: 10]   Train loss: 0.613  |  Test loss: 3.465  |  Test accuracy: 0.576  |\n",
      "|  [Epoch: 8, Batch: 20]   Train loss: 0.472  |  Test loss: 3.455  |  Test accuracy: 0.596  |\n",
      "|  [Epoch: 8, Batch: 30]   Train loss: 0.474  |  Test loss: 3.443  |  Test accuracy: 0.605  |\n",
      "|  [Epoch: 8, Batch: 40]   Train loss: 0.471  |  Test loss: 3.460  |  Test accuracy: 0.591  |\n",
      "|  [Epoch: 8, Batch: 50]   Train loss: 0.469  |  Test loss: 3.486  |  Test accuracy: 0.556  |\n",
      "|  [Epoch: 8, Batch: 60]   Train loss: 0.473  |  Test loss: 3.464  |  Test accuracy: 0.579  |\n",
      "|  [Epoch: 8, Batch: 70]   Train loss: 0.471  |  Test loss: 3.432  |  Test accuracy: 0.616  |\n",
      "|  [Epoch: 8, Batch: 80]   Train loss: 0.470  |  Test loss: 3.453  |  Test accuracy: 0.596  |\n",
      "|  [Epoch: 9, Batch: 10]   Train loss: 0.611  |  Test loss: 3.469  |  Test accuracy: 0.575  |\n",
      "|  [Epoch: 9, Batch: 20]   Train loss: 0.472  |  Test loss: 3.438  |  Test accuracy: 0.607  |\n",
      "|  [Epoch: 9, Batch: 30]   Train loss: 0.467  |  Test loss: 3.411  |  Test accuracy: 0.625  |\n",
      "|  [Epoch: 9, Batch: 40]   Train loss: 0.462  |  Test loss: 3.424  |  Test accuracy: 0.621  |\n",
      "|  [Epoch: 9, Batch: 50]   Train loss: 0.471  |  Test loss: 3.401  |  Test accuracy: 0.639  |\n",
      "|  [Epoch: 9, Batch: 60]   Train loss: 0.468  |  Test loss: 3.406  |  Test accuracy: 0.630  |\n",
      "|  [Epoch: 9, Batch: 70]   Train loss: 0.470  |  Test loss: 3.410  |  Test accuracy: 0.633  |\n",
      "|  [Epoch: 9, Batch: 80]   Train loss: 0.467  |  Test loss: 3.430  |  Test accuracy: 0.619  |\n",
      "|  [Epoch: 10, Batch: 10]   Train loss: 0.610  |  Test loss: 3.409  |  Test accuracy: 0.634  |\n",
      "|  [Epoch: 10, Batch: 20]   Train loss: 0.464  |  Test loss: 3.429  |  Test accuracy: 0.619  |\n",
      "|  [Epoch: 10, Batch: 30]   Train loss: 0.470  |  Test loss: 3.442  |  Test accuracy: 0.601  |\n",
      "|  [Epoch: 10, Batch: 40]   Train loss: 0.467  |  Test loss: 3.454  |  Test accuracy: 0.591  |\n",
      "|  [Epoch: 10, Batch: 50]   Train loss: 0.468  |  Test loss: 3.398  |  Test accuracy: 0.642  |\n",
      "|  [Epoch: 10, Batch: 60]   Train loss: 0.470  |  Test loss: 3.403  |  Test accuracy: 0.633  |\n",
      "|  [Epoch: 10, Batch: 70]   Train loss: 0.468  |  Test loss: 3.420  |  Test accuracy: 0.619  |\n",
      "|  [Epoch: 10, Batch: 80]   Train loss: 0.468  |  Test loss: 3.412  |  Test accuracy: 0.626  |\n",
      "|  [Epoch: 11, Batch: 10]   Train loss: 0.609  |  Test loss: 3.422  |  Test accuracy: 0.618  |\n",
      "|  [Epoch: 11, Batch: 20]   Train loss: 0.467  |  Test loss: 3.402  |  Test accuracy: 0.634  |\n",
      "|  [Epoch: 11, Batch: 30]   Train loss: 0.464  |  Test loss: 3.429  |  Test accuracy: 0.608  |\n",
      "|  [Epoch: 11, Batch: 40]   Train loss: 0.468  |  Test loss: 3.387  |  Test accuracy: 0.648  |\n",
      "|  [Epoch: 11, Batch: 50]   Train loss: 0.466  |  Test loss: 3.391  |  Test accuracy: 0.648  |\n",
      "|  [Epoch: 11, Batch: 60]   Train loss: 0.462  |  Test loss: 3.387  |  Test accuracy: 0.653  |\n",
      "|  [Epoch: 11, Batch: 70]   Train loss: 0.465  |  Test loss: 3.388  |  Test accuracy: 0.647  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  [Epoch: 11, Batch: 80]   Train loss: 0.462  |  Test loss: 3.437  |  Test accuracy: 0.603  |\n",
      "|  [Epoch: 12, Batch: 10]   Train loss: 0.605  |  Test loss: 3.435  |  Test accuracy: 0.605  |\n",
      "|  [Epoch: 12, Batch: 20]   Train loss: 0.462  |  Test loss: 3.413  |  Test accuracy: 0.628  |\n",
      "|  [Epoch: 12, Batch: 30]   Train loss: 0.462  |  Test loss: 3.399  |  Test accuracy: 0.633  |\n",
      "|  [Epoch: 12, Batch: 40]   Train loss: 0.466  |  Test loss: 3.383  |  Test accuracy: 0.647  |\n",
      "|  [Epoch: 12, Batch: 50]   Train loss: 0.463  |  Test loss: 3.405  |  Test accuracy: 0.629  |\n",
      "|  [Epoch: 12, Batch: 60]   Train loss: 0.466  |  Test loss: 3.389  |  Test accuracy: 0.648  |\n",
      "|  [Epoch: 12, Batch: 70]   Train loss: 0.470  |  Test loss: 3.387  |  Test accuracy: 0.649  |\n",
      "|  [Epoch: 12, Batch: 80]   Train loss: 0.469  |  Test loss: 3.379  |  Test accuracy: 0.655  |\n",
      "|  [Epoch: 13, Batch: 10]   Train loss: 0.603  |  Test loss: 3.423  |  Test accuracy: 0.625  |\n",
      "|  [Epoch: 13, Batch: 20]   Train loss: 0.464  |  Test loss: 3.395  |  Test accuracy: 0.644  |\n",
      "|  [Epoch: 13, Batch: 30]   Train loss: 0.461  |  Test loss: 3.385  |  Test accuracy: 0.656  |\n",
      "|  [Epoch: 13, Batch: 40]   Train loss: 0.466  |  Test loss: 3.375  |  Test accuracy: 0.660  |\n",
      "|  [Epoch: 13, Batch: 50]   Train loss: 0.467  |  Test loss: 3.387  |  Test accuracy: 0.652  |\n",
      "|  [Epoch: 13, Batch: 60]   Train loss: 0.463  |  Test loss: 3.380  |  Test accuracy: 0.658  |\n",
      "|  [Epoch: 13, Batch: 70]   Train loss: 0.465  |  Test loss: 3.394  |  Test accuracy: 0.640  |\n",
      "|  [Epoch: 13, Batch: 80]   Train loss: 0.467  |  Test loss: 3.382  |  Test accuracy: 0.653  |\n",
      "|  [Epoch: 14, Batch: 10]   Train loss: 0.603  |  Test loss: 3.457  |  Test accuracy: 0.590  |\n",
      "|  [Epoch: 14, Batch: 20]   Train loss: 0.466  |  Test loss: 3.387  |  Test accuracy: 0.647  |\n",
      "|  [Epoch: 14, Batch: 30]   Train loss: 0.463  |  Test loss: 3.372  |  Test accuracy: 0.660  |\n",
      "|  [Epoch: 14, Batch: 40]   Train loss: 0.464  |  Test loss: 3.364  |  Test accuracy: 0.668  |\n",
      "|  [Epoch: 14, Batch: 50]   Train loss: 0.469  |  Test loss: 3.377  |  Test accuracy: 0.653  |\n",
      "|  [Epoch: 14, Batch: 60]   Train loss: 0.465  |  Test loss: 3.414  |  Test accuracy: 0.620  |\n",
      "|  [Epoch: 14, Batch: 70]   Train loss: 0.468  |  Test loss: 3.406  |  Test accuracy: 0.630  |\n",
      "|  [Epoch: 14, Batch: 80]   Train loss: 0.466  |  Test loss: 3.389  |  Test accuracy: 0.644  |\n",
      "|  [Epoch: 15, Batch: 10]   Train loss: 0.608  |  Test loss: 3.385  |  Test accuracy: 0.649  |\n",
      "|  [Epoch: 15, Batch: 20]   Train loss: 0.462  |  Test loss: 3.376  |  Test accuracy: 0.659  |\n",
      "|  [Epoch: 15, Batch: 30]   Train loss: 0.466  |  Test loss: 3.364  |  Test accuracy: 0.666  |\n",
      "|  [Epoch: 15, Batch: 40]   Train loss: 0.469  |  Test loss: 3.365  |  Test accuracy: 0.667  |\n",
      "|  [Epoch: 15, Batch: 50]   Train loss: 0.466  |  Test loss: 3.370  |  Test accuracy: 0.662  |\n",
      "|  [Epoch: 15, Batch: 60]   Train loss: 0.465  |  Test loss: 3.370  |  Test accuracy: 0.662  |\n",
      "|  [Epoch: 15, Batch: 70]   Train loss: 0.465  |  Test loss: 3.370  |  Test accuracy: 0.662  |\n",
      "|  [Epoch: 15, Batch: 80]   Train loss: 0.464  |  Test loss: 3.358  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 16, Batch: 10]   Train loss: 0.604  |  Test loss: 3.352  |  Test accuracy: 0.678  |\n",
      "|  [Epoch: 16, Batch: 20]   Train loss: 0.461  |  Test loss: 3.381  |  Test accuracy: 0.653  |\n",
      "|  [Epoch: 16, Batch: 30]   Train loss: 0.463  |  Test loss: 3.390  |  Test accuracy: 0.645  |\n",
      "|  [Epoch: 16, Batch: 40]   Train loss: 0.461  |  Test loss: 3.359  |  Test accuracy: 0.675  |\n",
      "|  [Epoch: 16, Batch: 50]   Train loss: 0.464  |  Test loss: 3.356  |  Test accuracy: 0.678  |\n",
      "|  [Epoch: 16, Batch: 60]   Train loss: 0.462  |  Test loss: 3.353  |  Test accuracy: 0.677  |\n",
      "|  [Epoch: 16, Batch: 70]   Train loss: 0.467  |  Test loss: 3.359  |  Test accuracy: 0.669  |\n",
      "|  [Epoch: 16, Batch: 80]   Train loss: 0.462  |  Test loss: 3.362  |  Test accuracy: 0.669  |\n",
      "|  [Epoch: 17, Batch: 10]   Train loss: 0.600  |  Test loss: 3.370  |  Test accuracy: 0.658  |\n",
      "|  [Epoch: 17, Batch: 20]   Train loss: 0.467  |  Test loss: 3.353  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 17, Batch: 30]   Train loss: 0.462  |  Test loss: 3.346  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 17, Batch: 40]   Train loss: 0.464  |  Test loss: 3.359  |  Test accuracy: 0.670  |\n",
      "|  [Epoch: 17, Batch: 50]   Train loss: 0.465  |  Test loss: 3.359  |  Test accuracy: 0.670  |\n",
      "|  [Epoch: 17, Batch: 60]   Train loss: 0.464  |  Test loss: 3.369  |  Test accuracy: 0.664  |\n",
      "|  [Epoch: 17, Batch: 70]   Train loss: 0.464  |  Test loss: 3.375  |  Test accuracy: 0.657  |\n",
      "|  [Epoch: 17, Batch: 80]   Train loss: 0.464  |  Test loss: 3.376  |  Test accuracy: 0.656  |\n",
      "|  [Epoch: 18, Batch: 10]   Train loss: 0.607  |  Test loss: 3.364  |  Test accuracy: 0.668  |\n",
      "|  [Epoch: 18, Batch: 20]   Train loss: 0.466  |  Test loss: 3.364  |  Test accuracy: 0.668  |\n",
      "|  [Epoch: 18, Batch: 30]   Train loss: 0.464  |  Test loss: 3.360  |  Test accuracy: 0.668  |\n",
      "|  [Epoch: 18, Batch: 40]   Train loss: 0.461  |  Test loss: 3.347  |  Test accuracy: 0.682  |\n",
      "|  [Epoch: 18, Batch: 50]   Train loss: 0.465  |  Test loss: 3.350  |  Test accuracy: 0.682  |\n",
      "|  [Epoch: 18, Batch: 60]   Train loss: 0.464  |  Test loss: 3.349  |  Test accuracy: 0.682  |\n",
      "|  [Epoch: 18, Batch: 70]   Train loss: 0.463  |  Test loss: 3.352  |  Test accuracy: 0.677  |\n",
      "|  [Epoch: 18, Batch: 80]   Train loss: 0.464  |  Test loss: 3.367  |  Test accuracy: 0.664  |\n",
      "|  [Epoch: 19, Batch: 10]   Train loss: 0.605  |  Test loss: 3.361  |  Test accuracy: 0.669  |\n",
      "|  [Epoch: 19, Batch: 20]   Train loss: 0.462  |  Test loss: 3.361  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 19, Batch: 30]   Train loss: 0.463  |  Test loss: 3.362  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 19, Batch: 40]   Train loss: 0.463  |  Test loss: 3.359  |  Test accuracy: 0.673  |\n",
      "|  [Epoch: 19, Batch: 50]   Train loss: 0.466  |  Test loss: 3.356  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 19, Batch: 60]   Train loss: 0.463  |  Test loss: 3.357  |  Test accuracy: 0.670  |\n",
      "|  [Epoch: 19, Batch: 70]   Train loss: 0.461  |  Test loss: 3.355  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 19, Batch: 80]   Train loss: 0.465  |  Test loss: 3.350  |  Test accuracy: 0.682  |\n",
      "|  [Epoch: 20, Batch: 10]   Train loss: 0.603  |  Test loss: 3.351  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 20, Batch: 20]   Train loss: 0.464  |  Test loss: 3.352  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 20, Batch: 30]   Train loss: 0.463  |  Test loss: 3.349  |  Test accuracy: 0.681  |\n",
      "|  [Epoch: 20, Batch: 40]   Train loss: 0.467  |  Test loss: 3.349  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 20, Batch: 50]   Train loss: 0.465  |  Test loss: 3.344  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 20, Batch: 60]   Train loss: 0.464  |  Test loss: 3.357  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 20, Batch: 70]   Train loss: 0.462  |  Test loss: 3.353  |  Test accuracy: 0.678  |\n",
      "|  [Epoch: 20, Batch: 80]   Train loss: 0.464  |  Test loss: 3.355  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 21, Batch: 10]   Train loss: 0.603  |  Test loss: 3.355  |  Test accuracy: 0.673  |\n",
      "|  [Epoch: 21, Batch: 20]   Train loss: 0.463  |  Test loss: 3.353  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 21, Batch: 30]   Train loss: 0.462  |  Test loss: 3.358  |  Test accuracy: 0.670  |\n",
      "|  [Epoch: 21, Batch: 40]   Train loss: 0.462  |  Test loss: 3.355  |  Test accuracy: 0.677  |\n",
      "|  [Epoch: 21, Batch: 50]   Train loss: 0.461  |  Test loss: 3.356  |  Test accuracy: 0.672  |\n",
      "|  [Epoch: 21, Batch: 60]   Train loss: 0.462  |  Test loss: 3.356  |  Test accuracy: 0.675  |\n",
      "|  [Epoch: 21, Batch: 70]   Train loss: 0.463  |  Test loss: 3.356  |  Test accuracy: 0.672  |\n",
      "|  [Epoch: 21, Batch: 80]   Train loss: 0.462  |  Test loss: 3.351  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 22, Batch: 10]   Train loss: 0.606  |  Test loss: 3.356  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 22, Batch: 20]   Train loss: 0.466  |  Test loss: 3.356  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 22, Batch: 30]   Train loss: 0.463  |  Test loss: 3.359  |  Test accuracy: 0.669  |\n",
      "|  [Epoch: 22, Batch: 40]   Train loss: 0.463  |  Test loss: 3.348  |  Test accuracy: 0.683  |\n",
      "|  [Epoch: 22, Batch: 50]   Train loss: 0.462  |  Test loss: 3.350  |  Test accuracy: 0.680  |\n",
      "|  [Epoch: 22, Batch: 60]   Train loss: 0.462  |  Test loss: 3.352  |  Test accuracy: 0.675  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  [Epoch: 22, Batch: 70]   Train loss: 0.460  |  Test loss: 3.357  |  Test accuracy: 0.673  |\n",
      "|  [Epoch: 22, Batch: 80]   Train loss: 0.464  |  Test loss: 3.351  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 23, Batch: 10]   Train loss: 0.606  |  Test loss: 3.379  |  Test accuracy: 0.649  |\n",
      "|  [Epoch: 23, Batch: 20]   Train loss: 0.462  |  Test loss: 3.361  |  Test accuracy: 0.669  |\n",
      "|  [Epoch: 23, Batch: 30]   Train loss: 0.466  |  Test loss: 3.368  |  Test accuracy: 0.666  |\n",
      "|  [Epoch: 23, Batch: 40]   Train loss: 0.463  |  Test loss: 3.371  |  Test accuracy: 0.659  |\n",
      "|  [Epoch: 23, Batch: 50]   Train loss: 0.467  |  Test loss: 3.361  |  Test accuracy: 0.668  |\n",
      "|  [Epoch: 23, Batch: 60]   Train loss: 0.465  |  Test loss: 3.351  |  Test accuracy: 0.677  |\n",
      "|  [Epoch: 23, Batch: 70]   Train loss: 0.462  |  Test loss: 3.351  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 23, Batch: 80]   Train loss: 0.465  |  Test loss: 3.345  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 24, Batch: 10]   Train loss: 0.602  |  Test loss: 3.345  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 24, Batch: 20]   Train loss: 0.464  |  Test loss: 3.351  |  Test accuracy: 0.678  |\n",
      "|  [Epoch: 24, Batch: 30]   Train loss: 0.462  |  Test loss: 3.351  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 24, Batch: 40]   Train loss: 0.461  |  Test loss: 3.341  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 24, Batch: 50]   Train loss: 0.463  |  Test loss: 3.346  |  Test accuracy: 0.686  |\n",
      "|  [Epoch: 24, Batch: 60]   Train loss: 0.466  |  Test loss: 3.347  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 24, Batch: 70]   Train loss: 0.465  |  Test loss: 3.350  |  Test accuracy: 0.681  |\n",
      "|  [Epoch: 24, Batch: 80]   Train loss: 0.464  |  Test loss: 3.345  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 25, Batch: 10]   Train loss: 0.603  |  Test loss: 3.346  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 25, Batch: 20]   Train loss: 0.460  |  Test loss: 3.353  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 25, Batch: 30]   Train loss: 0.464  |  Test loss: 3.349  |  Test accuracy: 0.682  |\n",
      "|  [Epoch: 25, Batch: 40]   Train loss: 0.466  |  Test loss: 3.345  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 25, Batch: 50]   Train loss: 0.462  |  Test loss: 3.358  |  Test accuracy: 0.675  |\n",
      "|  [Epoch: 25, Batch: 60]   Train loss: 0.463  |  Test loss: 3.350  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 25, Batch: 70]   Train loss: 0.461  |  Test loss: 3.354  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 25, Batch: 80]   Train loss: 0.465  |  Test loss: 3.347  |  Test accuracy: 0.681  |\n",
      "|  [Epoch: 26, Batch: 10]   Train loss: 0.603  |  Test loss: 3.350  |  Test accuracy: 0.676  |\n",
      "|  [Epoch: 26, Batch: 20]   Train loss: 0.464  |  Test loss: 3.351  |  Test accuracy: 0.676  |\n",
      "|  [Epoch: 26, Batch: 30]   Train loss: 0.463  |  Test loss: 3.357  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 26, Batch: 40]   Train loss: 0.465  |  Test loss: 3.350  |  Test accuracy: 0.683  |\n",
      "|  [Epoch: 26, Batch: 50]   Train loss: 0.465  |  Test loss: 3.349  |  Test accuracy: 0.682  |\n",
      "|  [Epoch: 26, Batch: 60]   Train loss: 0.463  |  Test loss: 3.345  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 26, Batch: 70]   Train loss: 0.463  |  Test loss: 3.352  |  Test accuracy: 0.678  |\n",
      "|  [Epoch: 26, Batch: 80]   Train loss: 0.460  |  Test loss: 3.380  |  Test accuracy: 0.651  |\n",
      "|  [Epoch: 27, Batch: 10]   Train loss: 0.599  |  Test loss: 3.357  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 27, Batch: 20]   Train loss: 0.464  |  Test loss: 3.354  |  Test accuracy: 0.675  |\n",
      "|  [Epoch: 27, Batch: 30]   Train loss: 0.462  |  Test loss: 3.348  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 27, Batch: 40]   Train loss: 0.466  |  Test loss: 3.352  |  Test accuracy: 0.678  |\n",
      "|  [Epoch: 27, Batch: 50]   Train loss: 0.463  |  Test loss: 3.348  |  Test accuracy: 0.681  |\n",
      "|  [Epoch: 27, Batch: 60]   Train loss: 0.462  |  Test loss: 3.346  |  Test accuracy: 0.682  |\n",
      "|  [Epoch: 27, Batch: 70]   Train loss: 0.464  |  Test loss: 3.345  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 27, Batch: 80]   Train loss: 0.462  |  Test loss: 3.349  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 28, Batch: 10]   Train loss: 0.602  |  Test loss: 3.353  |  Test accuracy: 0.676  |\n",
      "|  [Epoch: 28, Batch: 20]   Train loss: 0.465  |  Test loss: 3.355  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 28, Batch: 30]   Train loss: 0.462  |  Test loss: 3.363  |  Test accuracy: 0.667  |\n",
      "|  [Epoch: 28, Batch: 40]   Train loss: 0.462  |  Test loss: 3.353  |  Test accuracy: 0.677  |\n",
      "|  [Epoch: 28, Batch: 50]   Train loss: 0.465  |  Test loss: 3.352  |  Test accuracy: 0.678  |\n",
      "|  [Epoch: 28, Batch: 60]   Train loss: 0.463  |  Test loss: 3.356  |  Test accuracy: 0.673  |\n",
      "|  [Epoch: 28, Batch: 70]   Train loss: 0.464  |  Test loss: 3.355  |  Test accuracy: 0.675  |\n",
      "|  [Epoch: 28, Batch: 80]   Train loss: 0.457  |  Test loss: 3.352  |  Test accuracy: 0.678  |\n",
      "|  [Epoch: 29, Batch: 10]   Train loss: 0.602  |  Test loss: 3.348  |  Test accuracy: 0.682  |\n",
      "|  [Epoch: 29, Batch: 20]   Train loss: 0.464  |  Test loss: 3.351  |  Test accuracy: 0.675  |\n",
      "|  [Epoch: 29, Batch: 30]   Train loss: 0.466  |  Test loss: 3.356  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 29, Batch: 40]   Train loss: 0.465  |  Test loss: 3.354  |  Test accuracy: 0.676  |\n",
      "|  [Epoch: 29, Batch: 50]   Train loss: 0.460  |  Test loss: 3.360  |  Test accuracy: 0.668  |\n",
      "|  [Epoch: 29, Batch: 60]   Train loss: 0.464  |  Test loss: 3.358  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 29, Batch: 70]   Train loss: 0.460  |  Test loss: 3.351  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 29, Batch: 80]   Train loss: 0.463  |  Test loss: 3.348  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 30, Batch: 10]   Train loss: 0.595  |  Test loss: 3.343  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 30, Batch: 20]   Train loss: 0.462  |  Test loss: 3.338  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 30, Batch: 30]   Train loss: 0.461  |  Test loss: 3.353  |  Test accuracy: 0.676  |\n",
      "|  [Epoch: 30, Batch: 40]   Train loss: 0.465  |  Test loss: 3.358  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 30, Batch: 50]   Train loss: 0.461  |  Test loss: 3.361  |  Test accuracy: 0.669  |\n",
      "|  [Epoch: 30, Batch: 60]   Train loss: 0.460  |  Test loss: 3.361  |  Test accuracy: 0.667  |\n",
      "|  [Epoch: 30, Batch: 70]   Train loss: 0.461  |  Test loss: 3.348  |  Test accuracy: 0.679  |\n",
      "|  [Epoch: 30, Batch: 80]   Train loss: 0.464  |  Test loss: 3.354  |  Test accuracy: 0.675  |\n",
      "|  [Epoch: 31, Batch: 10]   Train loss: 0.604  |  Test loss: 3.358  |  Test accuracy: 0.671  |\n",
      "|  [Epoch: 31, Batch: 20]   Train loss: 0.460  |  Test loss: 3.354  |  Test accuracy: 0.674  |\n",
      "|  [Epoch: 31, Batch: 30]   Train loss: 0.460  |  Test loss: 3.344  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 31, Batch: 40]   Train loss: 0.468  |  Test loss: 3.350  |  Test accuracy: 0.681  |\n",
      "|  [Epoch: 31, Batch: 50]   Train loss: 0.467  |  Test loss: 3.343  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 31, Batch: 60]   Train loss: 0.462  |  Test loss: 3.350  |  Test accuracy: 0.677  |\n",
      "|  [Epoch: 31, Batch: 70]   Train loss: 0.463  |  Test loss: 3.359  |  Test accuracy: 0.670  |\n",
      "|  [Epoch: 31, Batch: 80]   Train loss: 0.463  |  Test loss: 3.358  |  Test accuracy: 0.669  |\n",
      "|  [Epoch: 32, Batch: 10]   Train loss: 0.606  |  Test loss: 3.351  |  Test accuracy: 0.680  |\n",
      "|  [Epoch: 32, Batch: 20]   Train loss: 0.460  |  Test loss: 3.342  |  Test accuracy: 0.683  |\n",
      "|  [Epoch: 32, Batch: 30]   Train loss: 0.463  |  Test loss: 3.348  |  Test accuracy: 0.677  |\n",
      "|  [Epoch: 32, Batch: 40]   Train loss: 0.466  |  Test loss: 3.349  |  Test accuracy: 0.680  |\n",
      "|  [Epoch: 32, Batch: 50]   Train loss: 0.459  |  Test loss: 3.346  |  Test accuracy: 0.681  |\n",
      "|  [Epoch: 32, Batch: 60]   Train loss: 0.460  |  Test loss: 3.344  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 32, Batch: 70]   Train loss: 0.460  |  Test loss: 3.339  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 32, Batch: 80]   Train loss: 0.468  |  Test loss: 3.341  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 33, Batch: 10]   Train loss: 0.602  |  Test loss: 3.341  |  Test accuracy: 0.686  |\n",
      "|  [Epoch: 33, Batch: 20]   Train loss: 0.463  |  Test loss: 3.341  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 33, Batch: 30]   Train loss: 0.461  |  Test loss: 3.345  |  Test accuracy: 0.683  |\n",
      "|  [Epoch: 33, Batch: 40]   Train loss: 0.467  |  Test loss: 3.341  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 33, Batch: 50]   Train loss: 0.465  |  Test loss: 3.339  |  Test accuracy: 0.690  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  [Epoch: 33, Batch: 60]   Train loss: 0.461  |  Test loss: 3.342  |  Test accuracy: 0.686  |\n",
      "|  [Epoch: 33, Batch: 70]   Train loss: 0.463  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 33, Batch: 80]   Train loss: 0.467  |  Test loss: 3.344  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 34, Batch: 10]   Train loss: 0.606  |  Test loss: 3.346  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 34, Batch: 20]   Train loss: 0.464  |  Test loss: 3.351  |  Test accuracy: 0.680  |\n",
      "|  [Epoch: 34, Batch: 30]   Train loss: 0.466  |  Test loss: 3.338  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 34, Batch: 40]   Train loss: 0.460  |  Test loss: 3.342  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 34, Batch: 50]   Train loss: 0.463  |  Test loss: 3.342  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 34, Batch: 60]   Train loss: 0.459  |  Test loss: 3.339  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 34, Batch: 70]   Train loss: 0.460  |  Test loss: 3.336  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 34, Batch: 80]   Train loss: 0.462  |  Test loss: 3.339  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 35, Batch: 10]   Train loss: 0.601  |  Test loss: 3.339  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 35, Batch: 20]   Train loss: 0.466  |  Test loss: 3.341  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 35, Batch: 30]   Train loss: 0.463  |  Test loss: 3.341  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 35, Batch: 40]   Train loss: 0.462  |  Test loss: 3.338  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 35, Batch: 50]   Train loss: 0.464  |  Test loss: 3.341  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 35, Batch: 60]   Train loss: 0.461  |  Test loss: 3.338  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 35, Batch: 70]   Train loss: 0.462  |  Test loss: 3.337  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 35, Batch: 80]   Train loss: 0.463  |  Test loss: 3.337  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 36, Batch: 10]   Train loss: 0.601  |  Test loss: 3.341  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 36, Batch: 20]   Train loss: 0.459  |  Test loss: 3.342  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 36, Batch: 30]   Train loss: 0.460  |  Test loss: 3.340  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 36, Batch: 40]   Train loss: 0.464  |  Test loss: 3.342  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 36, Batch: 50]   Train loss: 0.462  |  Test loss: 3.340  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 36, Batch: 60]   Train loss: 0.460  |  Test loss: 3.341  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 36, Batch: 70]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 36, Batch: 80]   Train loss: 0.461  |  Test loss: 3.341  |  Test accuracy: 0.686  |\n",
      "|  [Epoch: 37, Batch: 10]   Train loss: 0.603  |  Test loss: 3.341  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 37, Batch: 20]   Train loss: 0.465  |  Test loss: 3.340  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 37, Batch: 30]   Train loss: 0.461  |  Test loss: 3.340  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 37, Batch: 40]   Train loss: 0.463  |  Test loss: 3.342  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 37, Batch: 50]   Train loss: 0.461  |  Test loss: 3.337  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 37, Batch: 60]   Train loss: 0.462  |  Test loss: 3.339  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 37, Batch: 70]   Train loss: 0.462  |  Test loss: 3.335  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 37, Batch: 80]   Train loss: 0.463  |  Test loss: 3.338  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 38, Batch: 10]   Train loss: 0.600  |  Test loss: 3.339  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 38, Batch: 20]   Train loss: 0.462  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 38, Batch: 30]   Train loss: 0.463  |  Test loss: 3.341  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 38, Batch: 40]   Train loss: 0.464  |  Test loss: 3.334  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 38, Batch: 50]   Train loss: 0.463  |  Test loss: 3.340  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 38, Batch: 60]   Train loss: 0.464  |  Test loss: 3.339  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 38, Batch: 70]   Train loss: 0.466  |  Test loss: 3.335  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 38, Batch: 80]   Train loss: 0.459  |  Test loss: 3.337  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 39, Batch: 10]   Train loss: 0.606  |  Test loss: 3.334  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 39, Batch: 20]   Train loss: 0.459  |  Test loss: 3.338  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 39, Batch: 30]   Train loss: 0.461  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 39, Batch: 40]   Train loss: 0.465  |  Test loss: 3.338  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 39, Batch: 50]   Train loss: 0.461  |  Test loss: 3.342  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 39, Batch: 60]   Train loss: 0.463  |  Test loss: 3.336  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 39, Batch: 70]   Train loss: 0.462  |  Test loss: 3.342  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 39, Batch: 80]   Train loss: 0.461  |  Test loss: 3.340  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 40, Batch: 10]   Train loss: 0.601  |  Test loss: 3.335  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 40, Batch: 20]   Train loss: 0.460  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 40, Batch: 30]   Train loss: 0.461  |  Test loss: 3.341  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 40, Batch: 40]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 40, Batch: 50]   Train loss: 0.463  |  Test loss: 3.339  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 40, Batch: 60]   Train loss: 0.462  |  Test loss: 3.334  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 40, Batch: 70]   Train loss: 0.460  |  Test loss: 3.340  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 40, Batch: 80]   Train loss: 0.459  |  Test loss: 3.336  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 41, Batch: 10]   Train loss: 0.596  |  Test loss: 3.335  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 41, Batch: 20]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 41, Batch: 30]   Train loss: 0.462  |  Test loss: 3.338  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 41, Batch: 40]   Train loss: 0.462  |  Test loss: 3.338  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 41, Batch: 50]   Train loss: 0.464  |  Test loss: 3.336  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 41, Batch: 60]   Train loss: 0.464  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 41, Batch: 70]   Train loss: 0.466  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 41, Batch: 80]   Train loss: 0.465  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 42, Batch: 10]   Train loss: 0.600  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 42, Batch: 20]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 42, Batch: 30]   Train loss: 0.462  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 42, Batch: 40]   Train loss: 0.460  |  Test loss: 3.335  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 42, Batch: 50]   Train loss: 0.462  |  Test loss: 3.334  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 42, Batch: 60]   Train loss: 0.461  |  Test loss: 3.329  |  Test accuracy: 0.701  |\n",
      "|  [Epoch: 42, Batch: 70]   Train loss: 0.465  |  Test loss: 3.334  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 42, Batch: 80]   Train loss: 0.461  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 43, Batch: 10]   Train loss: 0.600  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 43, Batch: 20]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 43, Batch: 30]   Train loss: 0.464  |  Test loss: 3.335  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 43, Batch: 40]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 43, Batch: 50]   Train loss: 0.458  |  Test loss: 3.335  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 43, Batch: 60]   Train loss: 0.464  |  Test loss: 3.331  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 43, Batch: 70]   Train loss: 0.462  |  Test loss: 3.337  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 43, Batch: 80]   Train loss: 0.458  |  Test loss: 3.332  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 44, Batch: 10]   Train loss: 0.603  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 44, Batch: 20]   Train loss: 0.461  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 44, Batch: 30]   Train loss: 0.460  |  Test loss: 3.332  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 44, Batch: 40]   Train loss: 0.460  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  [Epoch: 44, Batch: 50]   Train loss: 0.463  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 44, Batch: 60]   Train loss: 0.461  |  Test loss: 3.341  |  Test accuracy: 0.685  |\n",
      "|  [Epoch: 44, Batch: 70]   Train loss: 0.460  |  Test loss: 3.330  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 44, Batch: 80]   Train loss: 0.465  |  Test loss: 3.328  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 45, Batch: 10]   Train loss: 0.604  |  Test loss: 3.338  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 45, Batch: 20]   Train loss: 0.460  |  Test loss: 3.328  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 45, Batch: 30]   Train loss: 0.462  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 45, Batch: 40]   Train loss: 0.462  |  Test loss: 3.335  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 45, Batch: 50]   Train loss: 0.463  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 45, Batch: 60]   Train loss: 0.464  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 45, Batch: 70]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 45, Batch: 80]   Train loss: 0.460  |  Test loss: 3.330  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 46, Batch: 10]   Train loss: 0.604  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 46, Batch: 20]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 46, Batch: 30]   Train loss: 0.459  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 46, Batch: 40]   Train loss: 0.463  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 46, Batch: 50]   Train loss: 0.464  |  Test loss: 3.330  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 46, Batch: 60]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 46, Batch: 70]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 46, Batch: 80]   Train loss: 0.459  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 47, Batch: 10]   Train loss: 0.604  |  Test loss: 3.324  |  Test accuracy: 0.702  |\n",
      "|  [Epoch: 47, Batch: 20]   Train loss: 0.462  |  Test loss: 3.336  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 47, Batch: 30]   Train loss: 0.459  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 47, Batch: 40]   Train loss: 0.461  |  Test loss: 3.334  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 47, Batch: 50]   Train loss: 0.465  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 47, Batch: 60]   Train loss: 0.467  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 47, Batch: 70]   Train loss: 0.456  |  Test loss: 3.328  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 47, Batch: 80]   Train loss: 0.464  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 48, Batch: 10]   Train loss: 0.600  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 48, Batch: 20]   Train loss: 0.461  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 48, Batch: 30]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 48, Batch: 40]   Train loss: 0.462  |  Test loss: 3.329  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 48, Batch: 50]   Train loss: 0.462  |  Test loss: 3.336  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 48, Batch: 60]   Train loss: 0.462  |  Test loss: 3.327  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 48, Batch: 70]   Train loss: 0.461  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 48, Batch: 80]   Train loss: 0.462  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 49, Batch: 10]   Train loss: 0.599  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 49, Batch: 20]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 49, Batch: 30]   Train loss: 0.457  |  Test loss: 3.337  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 49, Batch: 40]   Train loss: 0.460  |  Test loss: 3.334  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 49, Batch: 50]   Train loss: 0.468  |  Test loss: 3.328  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 49, Batch: 60]   Train loss: 0.461  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 49, Batch: 70]   Train loss: 0.462  |  Test loss: 3.330  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 49, Batch: 80]   Train loss: 0.462  |  Test loss: 3.328  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 50, Batch: 10]   Train loss: 0.603  |  Test loss: 3.337  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 50, Batch: 20]   Train loss: 0.465  |  Test loss: 3.335  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 50, Batch: 30]   Train loss: 0.458  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 50, Batch: 40]   Train loss: 0.462  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 50, Batch: 50]   Train loss: 0.460  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 50, Batch: 60]   Train loss: 0.462  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 50, Batch: 70]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 50, Batch: 80]   Train loss: 0.463  |  Test loss: 3.325  |  Test accuracy: 0.702  |\n",
      "|  [Epoch: 51, Batch: 10]   Train loss: 0.599  |  Test loss: 3.328  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 51, Batch: 20]   Train loss: 0.461  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 51, Batch: 30]   Train loss: 0.465  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 51, Batch: 40]   Train loss: 0.461  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 51, Batch: 50]   Train loss: 0.466  |  Test loss: 3.336  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 51, Batch: 60]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 51, Batch: 70]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 51, Batch: 80]   Train loss: 0.457  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 52, Batch: 10]   Train loss: 0.603  |  Test loss: 3.330  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 52, Batch: 20]   Train loss: 0.465  |  Test loss: 3.327  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 52, Batch: 30]   Train loss: 0.461  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 52, Batch: 40]   Train loss: 0.458  |  Test loss: 3.335  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 52, Batch: 50]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 52, Batch: 60]   Train loss: 0.464  |  Test loss: 3.328  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 52, Batch: 70]   Train loss: 0.462  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 52, Batch: 80]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 53, Batch: 10]   Train loss: 0.599  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 53, Batch: 20]   Train loss: 0.466  |  Test loss: 3.336  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 53, Batch: 30]   Train loss: 0.461  |  Test loss: 3.328  |  Test accuracy: 0.701  |\n",
      "|  [Epoch: 53, Batch: 40]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 53, Batch: 50]   Train loss: 0.461  |  Test loss: 3.330  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 53, Batch: 60]   Train loss: 0.460  |  Test loss: 3.331  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 53, Batch: 70]   Train loss: 0.456  |  Test loss: 3.329  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 53, Batch: 80]   Train loss: 0.461  |  Test loss: 3.324  |  Test accuracy: 0.705  |\n",
      "|  [Epoch: 54, Batch: 10]   Train loss: 0.603  |  Test loss: 3.331  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 54, Batch: 20]   Train loss: 0.461  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 54, Batch: 30]   Train loss: 0.458  |  Test loss: 3.328  |  Test accuracy: 0.701  |\n",
      "|  [Epoch: 54, Batch: 40]   Train loss: 0.463  |  Test loss: 3.328  |  Test accuracy: 0.701  |\n",
      "|  [Epoch: 54, Batch: 50]   Train loss: 0.461  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 54, Batch: 60]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 54, Batch: 70]   Train loss: 0.465  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 54, Batch: 80]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 55, Batch: 10]   Train loss: 0.604  |  Test loss: 3.334  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 55, Batch: 20]   Train loss: 0.461  |  Test loss: 3.331  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 55, Batch: 30]   Train loss: 0.465  |  Test loss: 3.335  |  Test accuracy: 0.697  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  [Epoch: 55, Batch: 40]   Train loss: 0.460  |  Test loss: 3.342  |  Test accuracy: 0.684  |\n",
      "|  [Epoch: 55, Batch: 50]   Train loss: 0.459  |  Test loss: 3.338  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 55, Batch: 60]   Train loss: 0.462  |  Test loss: 3.337  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 55, Batch: 70]   Train loss: 0.462  |  Test loss: 3.336  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 55, Batch: 80]   Train loss: 0.467  |  Test loss: 3.340  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 56, Batch: 10]   Train loss: 0.603  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 56, Batch: 20]   Train loss: 0.464  |  Test loss: 3.337  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 56, Batch: 30]   Train loss: 0.461  |  Test loss: 3.329  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 56, Batch: 40]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 56, Batch: 50]   Train loss: 0.461  |  Test loss: 3.339  |  Test accuracy: 0.686  |\n",
      "|  [Epoch: 56, Batch: 60]   Train loss: 0.459  |  Test loss: 3.338  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 56, Batch: 70]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 56, Batch: 80]   Train loss: 0.462  |  Test loss: 3.334  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 57, Batch: 10]   Train loss: 0.599  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 57, Batch: 20]   Train loss: 0.459  |  Test loss: 3.337  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 57, Batch: 30]   Train loss: 0.462  |  Test loss: 3.333  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 57, Batch: 40]   Train loss: 0.466  |  Test loss: 3.335  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 57, Batch: 50]   Train loss: 0.467  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 57, Batch: 60]   Train loss: 0.461  |  Test loss: 3.335  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 57, Batch: 70]   Train loss: 0.462  |  Test loss: 3.331  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 57, Batch: 80]   Train loss: 0.469  |  Test loss: 3.335  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 58, Batch: 10]   Train loss: 0.601  |  Test loss: 3.330  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 58, Batch: 20]   Train loss: 0.462  |  Test loss: 3.341  |  Test accuracy: 0.688  |\n",
      "|  [Epoch: 58, Batch: 30]   Train loss: 0.462  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 58, Batch: 40]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 58, Batch: 50]   Train loss: 0.460  |  Test loss: 3.334  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 58, Batch: 60]   Train loss: 0.461  |  Test loss: 3.329  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 58, Batch: 70]   Train loss: 0.457  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 58, Batch: 80]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 59, Batch: 10]   Train loss: 0.604  |  Test loss: 3.328  |  Test accuracy: 0.701  |\n",
      "|  [Epoch: 59, Batch: 20]   Train loss: 0.465  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 59, Batch: 30]   Train loss: 0.462  |  Test loss: 3.334  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 59, Batch: 40]   Train loss: 0.460  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 59, Batch: 50]   Train loss: 0.464  |  Test loss: 3.331  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 59, Batch: 60]   Train loss: 0.465  |  Test loss: 3.334  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 59, Batch: 70]   Train loss: 0.461  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 59, Batch: 80]   Train loss: 0.461  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 60, Batch: 10]   Train loss: 0.602  |  Test loss: 3.335  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 60, Batch: 20]   Train loss: 0.461  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 60, Batch: 30]   Train loss: 0.465  |  Test loss: 3.327  |  Test accuracy: 0.701  |\n",
      "|  [Epoch: 60, Batch: 40]   Train loss: 0.465  |  Test loss: 3.330  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 60, Batch: 50]   Train loss: 0.465  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 60, Batch: 60]   Train loss: 0.463  |  Test loss: 3.335  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 60, Batch: 70]   Train loss: 0.460  |  Test loss: 3.334  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 60, Batch: 80]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 61, Batch: 10]   Train loss: 0.603  |  Test loss: 3.331  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 61, Batch: 20]   Train loss: 0.460  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 61, Batch: 30]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 61, Batch: 40]   Train loss: 0.465  |  Test loss: 3.329  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 61, Batch: 50]   Train loss: 0.462  |  Test loss: 3.332  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 61, Batch: 60]   Train loss: 0.459  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 61, Batch: 70]   Train loss: 0.465  |  Test loss: 3.329  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 61, Batch: 80]   Train loss: 0.462  |  Test loss: 3.336  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 62, Batch: 10]   Train loss: 0.602  |  Test loss: 3.332  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 62, Batch: 20]   Train loss: 0.467  |  Test loss: 3.328  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 62, Batch: 30]   Train loss: 0.461  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 62, Batch: 40]   Train loss: 0.460  |  Test loss: 3.337  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 62, Batch: 50]   Train loss: 0.466  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 62, Batch: 60]   Train loss: 0.463  |  Test loss: 3.337  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 62, Batch: 70]   Train loss: 0.460  |  Test loss: 3.337  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 62, Batch: 80]   Train loss: 0.461  |  Test loss: 3.334  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 63, Batch: 10]   Train loss: 0.597  |  Test loss: 3.337  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 63, Batch: 20]   Train loss: 0.463  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 63, Batch: 30]   Train loss: 0.463  |  Test loss: 3.336  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 63, Batch: 40]   Train loss: 0.463  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 63, Batch: 50]   Train loss: 0.460  |  Test loss: 3.332  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 63, Batch: 60]   Train loss: 0.460  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 63, Batch: 70]   Train loss: 0.459  |  Test loss: 3.334  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 63, Batch: 80]   Train loss: 0.467  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 64, Batch: 10]   Train loss: 0.602  |  Test loss: 3.340  |  Test accuracy: 0.686  |\n",
      "|  [Epoch: 64, Batch: 20]   Train loss: 0.465  |  Test loss: 3.340  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 64, Batch: 30]   Train loss: 0.461  |  Test loss: 3.339  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 64, Batch: 40]   Train loss: 0.465  |  Test loss: 3.335  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 64, Batch: 50]   Train loss: 0.463  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 64, Batch: 60]   Train loss: 0.464  |  Test loss: 3.335  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 64, Batch: 70]   Train loss: 0.463  |  Test loss: 3.329  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 64, Batch: 80]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 65, Batch: 10]   Train loss: 0.600  |  Test loss: 3.330  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 65, Batch: 20]   Train loss: 0.462  |  Test loss: 3.326  |  Test accuracy: 0.703  |\n",
      "|  [Epoch: 65, Batch: 30]   Train loss: 0.462  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 65, Batch: 40]   Train loss: 0.461  |  Test loss: 3.327  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 65, Batch: 50]   Train loss: 0.468  |  Test loss: 3.330  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 65, Batch: 60]   Train loss: 0.460  |  Test loss: 3.334  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 65, Batch: 70]   Train loss: 0.465  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 65, Batch: 80]   Train loss: 0.461  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 66, Batch: 10]   Train loss: 0.600  |  Test loss: 3.328  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 66, Batch: 20]   Train loss: 0.462  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  [Epoch: 66, Batch: 30]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 66, Batch: 40]   Train loss: 0.459  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 66, Batch: 50]   Train loss: 0.461  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 66, Batch: 60]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 66, Batch: 70]   Train loss: 0.464  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 66, Batch: 80]   Train loss: 0.463  |  Test loss: 3.328  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 67, Batch: 10]   Train loss: 0.602  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 67, Batch: 20]   Train loss: 0.458  |  Test loss: 3.328  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 67, Batch: 30]   Train loss: 0.460  |  Test loss: 3.331  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 67, Batch: 40]   Train loss: 0.460  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 67, Batch: 50]   Train loss: 0.465  |  Test loss: 3.328  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 67, Batch: 60]   Train loss: 0.465  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 67, Batch: 70]   Train loss: 0.461  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 67, Batch: 80]   Train loss: 0.464  |  Test loss: 3.330  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 68, Batch: 10]   Train loss: 0.597  |  Test loss: 3.330  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 68, Batch: 20]   Train loss: 0.461  |  Test loss: 3.336  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 68, Batch: 30]   Train loss: 0.469  |  Test loss: 3.329  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 68, Batch: 40]   Train loss: 0.461  |  Test loss: 3.336  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 68, Batch: 50]   Train loss: 0.465  |  Test loss: 3.335  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 68, Batch: 60]   Train loss: 0.468  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 68, Batch: 70]   Train loss: 0.460  |  Test loss: 3.335  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 68, Batch: 80]   Train loss: 0.465  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 69, Batch: 10]   Train loss: 0.608  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 69, Batch: 20]   Train loss: 0.462  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 69, Batch: 30]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 69, Batch: 40]   Train loss: 0.463  |  Test loss: 3.334  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 69, Batch: 50]   Train loss: 0.459  |  Test loss: 3.327  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 69, Batch: 60]   Train loss: 0.463  |  Test loss: 3.330  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 69, Batch: 70]   Train loss: 0.461  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 69, Batch: 80]   Train loss: 0.460  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 70, Batch: 10]   Train loss: 0.600  |  Test loss: 3.329  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 70, Batch: 20]   Train loss: 0.463  |  Test loss: 3.327  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 70, Batch: 30]   Train loss: 0.461  |  Test loss: 3.327  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 70, Batch: 40]   Train loss: 0.463  |  Test loss: 3.329  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 70, Batch: 50]   Train loss: 0.464  |  Test loss: 3.327  |  Test accuracy: 0.701  |\n",
      "|  [Epoch: 70, Batch: 60]   Train loss: 0.460  |  Test loss: 3.328  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 70, Batch: 70]   Train loss: 0.458  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 70, Batch: 80]   Train loss: 0.457  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 71, Batch: 10]   Train loss: 0.597  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 71, Batch: 20]   Train loss: 0.465  |  Test loss: 3.328  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 71, Batch: 30]   Train loss: 0.462  |  Test loss: 3.322  |  Test accuracy: 0.704  |\n",
      "|  [Epoch: 71, Batch: 40]   Train loss: 0.465  |  Test loss: 3.334  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 71, Batch: 50]   Train loss: 0.468  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 71, Batch: 60]   Train loss: 0.462  |  Test loss: 3.328  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 71, Batch: 70]   Train loss: 0.462  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 71, Batch: 80]   Train loss: 0.463  |  Test loss: 3.328  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 72, Batch: 10]   Train loss: 0.604  |  Test loss: 3.336  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 72, Batch: 20]   Train loss: 0.461  |  Test loss: 3.328  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 72, Batch: 30]   Train loss: 0.469  |  Test loss: 3.336  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 72, Batch: 40]   Train loss: 0.460  |  Test loss: 3.336  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 72, Batch: 50]   Train loss: 0.461  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 72, Batch: 60]   Train loss: 0.461  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 72, Batch: 70]   Train loss: 0.457  |  Test loss: 3.330  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 72, Batch: 80]   Train loss: 0.461  |  Test loss: 3.330  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 73, Batch: 10]   Train loss: 0.596  |  Test loss: 3.335  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 73, Batch: 20]   Train loss: 0.461  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 73, Batch: 30]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 73, Batch: 40]   Train loss: 0.461  |  Test loss: 3.335  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 73, Batch: 50]   Train loss: 0.462  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 73, Batch: 60]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 73, Batch: 70]   Train loss: 0.463  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 73, Batch: 80]   Train loss: 0.461  |  Test loss: 3.327  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 74, Batch: 10]   Train loss: 0.599  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 74, Batch: 20]   Train loss: 0.464  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 74, Batch: 30]   Train loss: 0.464  |  Test loss: 3.335  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 74, Batch: 40]   Train loss: 0.465  |  Test loss: 3.327  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 74, Batch: 50]   Train loss: 0.462  |  Test loss: 3.335  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 74, Batch: 60]   Train loss: 0.465  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 74, Batch: 70]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 74, Batch: 80]   Train loss: 0.462  |  Test loss: 3.334  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 75, Batch: 10]   Train loss: 0.600  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 75, Batch: 20]   Train loss: 0.462  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 75, Batch: 30]   Train loss: 0.461  |  Test loss: 3.332  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 75, Batch: 40]   Train loss: 0.461  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 75, Batch: 50]   Train loss: 0.462  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 75, Batch: 60]   Train loss: 0.460  |  Test loss: 3.328  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 75, Batch: 70]   Train loss: 0.462  |  Test loss: 3.329  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 75, Batch: 80]   Train loss: 0.464  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 76, Batch: 10]   Train loss: 0.603  |  Test loss: 3.334  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 76, Batch: 20]   Train loss: 0.465  |  Test loss: 3.326  |  Test accuracy: 0.701  |\n",
      "|  [Epoch: 76, Batch: 30]   Train loss: 0.460  |  Test loss: 3.327  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 76, Batch: 40]   Train loss: 0.461  |  Test loss: 3.327  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 76, Batch: 50]   Train loss: 0.465  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 76, Batch: 60]   Train loss: 0.459  |  Test loss: 3.334  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 76, Batch: 70]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 76, Batch: 80]   Train loss: 0.461  |  Test loss: 3.335  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 77, Batch: 10]   Train loss: 0.604  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  [Epoch: 77, Batch: 20]   Train loss: 0.463  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 77, Batch: 30]   Train loss: 0.460  |  Test loss: 3.328  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 77, Batch: 40]   Train loss: 0.464  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 77, Batch: 50]   Train loss: 0.466  |  Test loss: 3.334  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 77, Batch: 60]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 77, Batch: 70]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 77, Batch: 80]   Train loss: 0.466  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 78, Batch: 10]   Train loss: 0.599  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 78, Batch: 20]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 78, Batch: 30]   Train loss: 0.461  |  Test loss: 3.330  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 78, Batch: 40]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 78, Batch: 50]   Train loss: 0.463  |  Test loss: 3.330  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 78, Batch: 60]   Train loss: 0.461  |  Test loss: 3.335  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 78, Batch: 70]   Train loss: 0.463  |  Test loss: 3.335  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 78, Batch: 80]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 79, Batch: 10]   Train loss: 0.600  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 79, Batch: 20]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 79, Batch: 30]   Train loss: 0.459  |  Test loss: 3.327  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 79, Batch: 40]   Train loss: 0.460  |  Test loss: 3.332  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 79, Batch: 50]   Train loss: 0.462  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 79, Batch: 60]   Train loss: 0.465  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 79, Batch: 70]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 79, Batch: 80]   Train loss: 0.460  |  Test loss: 3.332  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 80, Batch: 10]   Train loss: 0.597  |  Test loss: 3.328  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 80, Batch: 20]   Train loss: 0.463  |  Test loss: 3.334  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 80, Batch: 30]   Train loss: 0.464  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 80, Batch: 40]   Train loss: 0.461  |  Test loss: 3.329  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 80, Batch: 50]   Train loss: 0.461  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 80, Batch: 60]   Train loss: 0.464  |  Test loss: 3.331  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 80, Batch: 70]   Train loss: 0.462  |  Test loss: 3.332  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 80, Batch: 80]   Train loss: 0.464  |  Test loss: 3.328  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 81, Batch: 10]   Train loss: 0.605  |  Test loss: 3.330  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 81, Batch: 20]   Train loss: 0.463  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 81, Batch: 30]   Train loss: 0.464  |  Test loss: 3.335  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 81, Batch: 40]   Train loss: 0.462  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 81, Batch: 50]   Train loss: 0.460  |  Test loss: 3.335  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 81, Batch: 60]   Train loss: 0.465  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 81, Batch: 70]   Train loss: 0.466  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 81, Batch: 80]   Train loss: 0.459  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 82, Batch: 10]   Train loss: 0.597  |  Test loss: 3.331  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 82, Batch: 20]   Train loss: 0.464  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 82, Batch: 30]   Train loss: 0.465  |  Test loss: 3.334  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 82, Batch: 40]   Train loss: 0.464  |  Test loss: 3.337  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 82, Batch: 50]   Train loss: 0.464  |  Test loss: 3.328  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 82, Batch: 60]   Train loss: 0.462  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 82, Batch: 70]   Train loss: 0.460  |  Test loss: 3.327  |  Test accuracy: 0.698  |\n",
      "|  [Epoch: 82, Batch: 80]   Train loss: 0.463  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 83, Batch: 10]   Train loss: 0.603  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 83, Batch: 20]   Train loss: 0.461  |  Test loss: 3.325  |  Test accuracy: 0.702  |\n",
      "|  [Epoch: 83, Batch: 30]   Train loss: 0.459  |  Test loss: 3.336  |  Test accuracy: 0.689  |\n",
      "|  [Epoch: 83, Batch: 40]   Train loss: 0.459  |  Test loss: 3.332  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 83, Batch: 50]   Train loss: 0.463  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 83, Batch: 60]   Train loss: 0.463  |  Test loss: 3.328  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 83, Batch: 70]   Train loss: 0.465  |  Test loss: 3.334  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 83, Batch: 80]   Train loss: 0.463  |  Test loss: 3.335  |  Test accuracy: 0.690  |\n",
      "|  [Epoch: 84, Batch: 10]   Train loss: 0.599  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 84, Batch: 20]   Train loss: 0.462  |  Test loss: 3.325  |  Test accuracy: 0.700  |\n",
      "|  [Epoch: 84, Batch: 30]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 84, Batch: 40]   Train loss: 0.464  |  Test loss: 3.331  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 84, Batch: 50]   Train loss: 0.465  |  Test loss: 3.330  |  Test accuracy: 0.694  |\n",
      "|  [Epoch: 84, Batch: 60]   Train loss: 0.464  |  Test loss: 3.329  |  Test accuracy: 0.697  |\n",
      "|  [Epoch: 84, Batch: 70]   Train loss: 0.464  |  Test loss: 3.333  |  Test accuracy: 0.692  |\n",
      "|  [Epoch: 84, Batch: 80]   Train loss: 0.464  |  Test loss: 3.330  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 85, Batch: 10]   Train loss: 0.603  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 85, Batch: 20]   Train loss: 0.461  |  Test loss: 3.334  |  Test accuracy: 0.691  |\n",
      "|  [Epoch: 85, Batch: 30]   Train loss: 0.459  |  Test loss: 3.332  |  Test accuracy: 0.695  |\n",
      "|  [Epoch: 85, Batch: 40]   Train loss: 0.460  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 85, Batch: 50]   Train loss: 0.465  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n",
      "|  [Epoch: 85, Batch: 60]   Train loss: 0.463  |  Test loss: 3.333  |  Test accuracy: 0.693  |\n",
      "|  [Epoch: 85, Batch: 70]   Train loss: 0.457  |  Test loss: 3.327  |  Test accuracy: 0.699  |\n",
      "|  [Epoch: 85, Batch: 80]   Train loss: 0.465  |  Test loss: 3.329  |  Test accuracy: 0.696  |\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv11 = nn.Conv2d(in_channels=num_output_channels, out_channels=20, kernel_size=5, padding=2)\n",
    "        self.conv12 = nn.Conv2d(20, 20, 5, padding=2)\n",
    "        self.batch1 = nn.BatchNorm2d(20)\n",
    "        self.pool1  = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv21 = nn.Conv2d(20, 40, 5, padding=2)\n",
    "        self.conv22 = nn.Conv2d(40, 40, 5, padding=2)\n",
    "        self.batch2 = nn.BatchNorm2d(40)\n",
    "        self.pool2  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # Transitioning from Conv ===> Linear\n",
    "        # 16 is the number of output channels in the previous conv layer.\n",
    "        \n",
    "        self.fc1 = nn.Linear(40 * 8 * 8, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, len(classes))\n",
    "        self.dropconv = nn.Dropout(0.2)\n",
    "        self.dropfc = nn.Dropout(0.4)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = self.batch1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv21(x))\n",
    "        x = F.relu(self.conv22(x))\n",
    "        x = self.batch2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 40 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropfc(x)\n",
    "        x = self.soft(x)\n",
    "        return x\n",
    "\n",
    "# init the class \n",
    "model = Net()\n",
    "print(model)\n",
    "model.eval()\n",
    "inp = torch.randn((1,1,32,32))\n",
    "out = model(inp)\n",
    "\n",
    "#model.load_state_dict(torch.load('./models/custom_label_1000.pt'))\n",
    "model.train()\n",
    "import torch.optim as optim\n",
    "\n",
    "# set parameters\n",
    "learning_rate = 0.001 #0.005\n",
    "momentum = 0.9\n",
    "\n",
    "def loss_optim():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.MSELoss()\n",
    "    #criterion = nn.NLLLoss()\n",
    "    # Adam Max\n",
    "    #optimizer = torch.optim.Adamax(model.parameters(), learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "    # Adam\n",
    "    optimizer = optim.Adam(model.parameters(), learning_rate, amsgrad = True)\n",
    "    # SGD. Momentum = remembering previous estimation change for a param (delta W)\n",
    "    #optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "    return criterion, optimizer\n",
    "\n",
    "criterion, optimizer = loss_optim()\n",
    "print(criterion)\n",
    "print(optimizer)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def train_network():\n",
    "    \n",
    "    # Choose parameters\n",
    "    num_epoch = 100\n",
    "    mini_batch = 10 # previously batch_size\n",
    "    train_losses, test_losses = [], []\n",
    "    running_loss = 0\n",
    "    for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            # convert to float bc softmax doesn't work with long\n",
    "            inputs = torch.tensor(inputs, dtype=torch.float)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # print statistics\n",
    "            if i % mini_batch == mini_batch-1:    # print every # of mini-batches\n",
    "                test_loss = 0\n",
    "                accuracy = 0\n",
    "                # begin evaluation of validation loss\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for inputs_test, labels_test in testloader:\n",
    "                        if labels_test.size()[0] == batch_size:\n",
    "                            ps = model.forward(inputs_test)\n",
    "                            batch_loss = criterion(ps, labels_test)\n",
    "                            test_loss += batch_loss.item()\n",
    "                            top_p, top_class = ps.topk(1, dim=1)\n",
    "                            equals = top_class == labels_test.view(*top_class.shape)\n",
    "                            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                train_losses.append(running_loss/len(trainloader))\n",
    "                test_losses.append(test_loss/len(testloader))    \n",
    "                print(f\"|  [Epoch: {epoch + 1}, Batch: {i + 1}]   \"\n",
    "                      f\"Train loss: {running_loss/len(trainloader):.3f}  |  \"\n",
    "                      f\"Test loss: {test_loss/len(testloader):.3f}  |  \"\n",
    "                      f\"Test accuracy: {accuracy/len(testloader):.3f}  |\")\n",
    "                running_loss = 0\n",
    "                model.train()\n",
    "            \n",
    "    \n",
    "    PATH = './models/custom_label_1001.pt'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    return train_losses, test_losses, PATH\n",
    "\n",
    "def visualize_train(train_losses, test_losses):\n",
    "     plt.plot(train_losses, label='Training loss')\n",
    "     plt.plot(test_losses, label='Test/Validation loss')\n",
    "     plt.legend(frameon=False)\n",
    "     plt.show()\n",
    "\n",
    "print(\"========================================BEGIN TRAINING=======================================\")\n",
    "train_losses, test_losses, PATH = train_network()\n",
    "print(\"=========================================END TRAINING========================================\")\n",
    "visualize_train(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
