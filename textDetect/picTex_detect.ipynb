{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PicTex Text Detection Model\n",
    "\n",
    "Len Huang. Given a square image of handwritten text, return its class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Dataset\n",
    "\n",
    "Taken from TowardsDataScience.\n",
    "https://discuss.pytorch.org/t/transforming-3-channel-image-to-greyscale-1-channel/48463/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes are:\n",
      "['(', ')', '+', ',', '=', 'a', 'ast', 'b', 'c', 'cong', 'd', 'e', 'f', 'full_stop', 'g', 'geq', 'h', 'i', 'iff', 'implies', 'j', 'k', 'l', 'leq', 'm', 'minus', 'n', 'neq', 'o', 'p', 'plus', 'q', 'r', 's', 'sum', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Train loader is:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x125112f10>\n",
      "Test loader is:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1251124d0>\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data_dir = 'datasets/our_images_final/'\n",
    "def load_split_train_test(datadir, valid_size = .2):\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize((32, 32)), \n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    train_data = datasets.ImageFolder(datadir, transform)\n",
    "    test_data = datasets.ImageFolder(datadir, transform)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=64)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=64)\n",
    "    return trainloader, testloader\n",
    "\n",
    "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "\n",
    "# WE'LL NEED TO DEFINE CLASSES FOR LATER\n",
    "classes = trainloader.dataset.classes\n",
    "print(\"Classes are:\")\n",
    "print(classes)\n",
    "print(\"Train loader is:\")\n",
    "print(trainloader)\n",
    "print(\"Test loader is:\")\n",
    "print(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.5? Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Image augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create CNN\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=42, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # idk what this does\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Transitioning from Conv ===> Linear\n",
    "        # 16 is the number of output channels in the previous conv layer.\n",
    "        # not sure what 5 is...\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, len(classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# init the class \n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Loss Function and Optimizer\n",
    "\n",
    "Adam/SGD and Cross Entrop Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# set parameters\n",
    "learning_rate = 0.001\n",
    "momentum = 0.8\n",
    "\n",
    "def loss_optim():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Adam\n",
    "    # optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "    # SGD. Momentum = remembering previous estimation change for a param (delta W)\n",
    "    optimizer = optim.SGD(model.parameters(), learning_rate, momentum)\n",
    "    return criterion, optimizer\n",
    "\n",
    "criterion, optimizer = loss_optim()\n",
    "print(criterion)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \n",
    "    # Choose parameters\n",
    "    num_epoch = 10\n",
    "    mini_batch = 10\n",
    "    train_losses, test_losses = [], []\n",
    "    running_loss = 0\n",
    "    \n",
    "    for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # print statistics\n",
    "            if i % mini_batch == mini_batch - 1:    # print every # of mini-batches\n",
    "                test_loss = 0\n",
    "                accuracy = 0\n",
    "                # begin evaluation of validation loss\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for inputs_test, labels_test in testloader:\n",
    "                        # GPU Optimization\n",
    "                        # inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        logps = model.forward(inputs)\n",
    "                        batch_loss = criterion(logps, labels)\n",
    "                        test_loss += batch_loss.item()\n",
    "                        ps = torch.exp(logps)\n",
    "                        top_p, top_class = ps.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                train_losses.append(running_loss/len(trainloader))\n",
    "                test_losses.append(test_loss/len(testloader))    \n",
    "                print(f\"|  [Epoch: {epoch + 1}, Batch: {i + 1}]   \"\n",
    "                      f\"Train loss: {running_loss/mini_batch:.3f}  |  \"\n",
    "                      f\"Test loss: {test_loss/len(testloader):.3f}  |  \"\n",
    "                      f\"Test accuracy: {accuracy/len(testloader):.3f}  |\")\n",
    "                running_loss = 0\n",
    "                model.train()\n",
    "            \n",
    "    \n",
    "    PATH = './models/pictex_text_detect.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    return train_losses, test_losses\n",
    "\n",
    "def visualize_train(train_losses, test_losses):\n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Test/Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "print(\"====================================BEGIN TRAINING====================================\")\n",
    "train_losses, test_losses = train_network()\n",
    "print(\"=====================================END TRAINING=====================================\")\n",
    "visualize_train(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test the Network\n",
    "\n",
    "https://stackoverflow.com/questions/13214809/pretty-print-2d-python-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as tvu\n",
    "\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy() # numpy-ify image\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Display Content in 8 rows 8 cols matrix\n",
    "def display_class(labels):\n",
    "    results = []\n",
    "    for i in range(8):\n",
    "        row = []\n",
    "        for j in range(8):\n",
    "            index = i + 1 * j\n",
    "            prediction = classes[labels[index]]\n",
    "            row.append(prediction)\n",
    "        results.append(row)\n",
    "    # Fancy code I found on StackOverflow\n",
    "    s = [[str(e) for e in row] for row in results]\n",
    "    lens = [max(map(len, col)) for col in zip(*s)]\n",
    "    fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "    table = [fmt.format(*row) for row in s]\n",
    "    print('\\n'.join(table))\n",
    "    \n",
    "        \n",
    "\n",
    "def test_data():\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # print images\n",
    "    imshow(tvu.make_grid(images))\n",
    "    display_class(labels)\n",
    "\n",
    "test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bita46fd814d558463baa988311c2514a7b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
